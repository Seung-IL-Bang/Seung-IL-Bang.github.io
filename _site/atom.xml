<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-25T21:30:02+09:00</updated><id>http://localhost:4000/atom.xml</id><title type="html">Seung il’s Blog</title><subtitle>방승일 깃헙 블로그</subtitle><author><name>Bang Seung IL</name></author><entry><title type="html">Spring Cloud Data Flow와 Kubernetes를 활용한 효과적인 배치 구동 환경 구축</title><link href="http://localhost:4000/spring%20batch/spring%20cloud%20data%20flow/kubernetes/2025/03/23/Spring-Batch-SCDF-k8s/" rel="alternate" type="text/html" title="Spring Cloud Data Flow와 Kubernetes를 활용한 효과적인 배치 구동 환경 구축" /><published>2025-03-23T00:00:00+09:00</published><updated>2025-03-23T00:00:00+09:00</updated><id>http://localhost:4000/spring%20batch/spring%20cloud%20data%20flow/kubernetes/2025/03/23/Spring-Batch-SCDF-k8s</id><content type="html" xml:base="http://localhost:4000/spring%20batch/spring%20cloud%20data%20flow/kubernetes/2025/03/23/Spring-Batch-SCDF-k8s/"><![CDATA[<blockquote>
  <p>Spring Cloud Data Flow와 Kuebernetes 연동하여 효과적인 배치 구동 환경에 대해 알아봅시다!</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">🚀 들어가기</h1>

<p>배치 작업은 현대 시스템의 핵심 부분으로, 특히 <strong>정산</strong>, <strong>로그 분석</strong>, <strong>데이터 마이그레이션</strong> 같은 작업들은 대용량 데이터를 효율적으로 처리해야 합니다. 이러한 배치 작업의 효율적인 관리와 모니터링은 시스템의 안정성과 성능에 직접적인 영향을 미칩니다. 이 글에서는 <strong>Spring Cloud Data Flow(SCDF)</strong>와 <strong>Kubernetes</strong>를 연동하여 효과적인 배치 구동 환경을 구축하는 방법에 대해 알아보겠습니다.</p>

<h1 id="1-기존-배치-스케줄링-도구의-한계">1. 기존 배치 스케줄링 도구의 한계</h1>

<p>많은 배치 작업의 스케줄링을 위해 크론(Cron), 젠킨스(Jenkins), 에어플로우(Airflow) 등을 사용해 배치를 스케줄링하고 있습니다.</p>

<p>이러한 도구들은 다음과 같은 기능을 제공합니다:</p>

<ul>
  <li>배치 실행 요청</li>
  <li>스케줄 관리</li>
  <li>배치 애플리케이션 관리</li>
  <li>워크플로우 관리 (배치 실행 순서 제어)</li>
  <li>모니터링 제공</li>
  <li>히스토리 저장 (메타 테이블)</li>
</ul>

<p>그러나 이러한 <strong>전통적인 스케줄링 도구들은 다음과 같은 두 가지 주용한 한계점</strong>을 가지고 있습니다.</p>

<h2 id="1-1-자원-관리의-어려움">1-1. 자원 관리의 어려움</h2>

<p>배치 작업은 특정 시간에만 동작하고, 완료되면 프로세스가 종료되어 자원을 운영체제에 반납합니다. 이로 인해 하루 중 시간대별로 자원 사용률이 크게 달라질 수 있습니다.</p>

<p>예를 들어:</p>

<ul>
  <li><strong>새벽 1시</strong>: 실행 중인 배치가 없어 자원이 남음</li>
  <li><strong>오전 9시</strong>: 4개의 배치가 동시에 실행되어 자원 사용률이 높음</li>
  <li><strong>오후 1시</strong>: 2개의 배치만 실행되어 자원 사용률이 중간 수준</li>
  <li><strong>오후 6시</strong>: 다시 1개의 배치만 실행되어 자원이 남음</li>
</ul>

<p>배치 작업이 항상 인스턴스로 떠 있는 것이 아니기 때문에, 자원 사용량을 예측하고 관리하는 것이 어렵습니다. 특히 동시에 <strong>여러 배치가 실행될 때는 자원 부족으로 OOM(Out of Memory) 오류</strong>가 발생할 수 있습니다.</p>

<h2 id="1-1-배치-상태-파악의-어려움">1-1. 배치 상태 파악의 어려움</h2>

<p>배치 작업의 각 단계는 일반적으로 매우 긴 시간이 소요됩니다. 예를 들어, 하나의 스텝이 시작되고 10분 이상 지나고나서야 완료되는 경우가 흔합니다. 대부분의 스케줄링 도구는 로그를 볼 수 있지만, 다음과 같은 한계가 있습니다:</p>

<ul>
  <li>배치 작업의 경우 로그 정보가 빈약한 경우가 많음</li>
  <li>로그만으로는 서비스 상태를 직관적으로 파악하기 어려움</li>
  <li>시각적인 모니터링 부재</li>
</ul>

<p>이러한 한계를 극복하고자 <strong>Spring Cloud Data Flow</strong>를 도입하는 것이 효과적입니다.</p>

<h1 id="2-spring-cloud-data-flow-소개">2. Spring Cloud Data Flow 소개</h1>

<p><strong>Spring Cloud Data Flow(SCDF)</strong>는 <strong>Spring Boot 기반</strong>의 데이터 통합 및 실시간 데이터 처리 애플리케이션을 개발하고 배포하기 위한 도구입니다.</p>

<p><strong>SCDF</strong>는 다음과 같은 주요 기능을 제공합니다:</p>

<ul>
  <li><strong>통합된 개발 및 관리 환경</strong>: 데이터 파이프라인과 배치 작업의 개발, 배포, 관리를 위한 통합 환경</li>
  <li><strong>시각적 디자인 인터페이스</strong>: 데이터 흐름 및 배치 작업을 시각적으로 설계</li>
  <li><strong>확장성</strong>: 다양한 런타임 플랫폼(Local, Cloud Foundry, Kubernetes) 지원</li>
  <li><strong>모니터링 및 관리</strong>: 작업 실행 상태 및 로그 모니터링, 작업 스케줄링</li>
</ul>

<p><strong>SCDF</strong>는 데이터 파이프라인 종류에 따라 두 가지 유형을 지원합니다:</p>

<ol>
  <li><strong>스트림(Stream)</strong>: 실시간 데이터 처리를 위한 파이프라인</li>
  <li><strong>태스크(Task)</strong>: 배치 작업을 지원하는 파이프라인</li>
</ol>

<p>⭐️ 배치 작업을 위한 <strong>SCDF Task</strong>는 <strong>기존 스케줄링 도구의 모든 기능과 더불어 다음 두 가지 핵심 장점을 제공</strong>합니다:</p>

<ol>
  <li><strong>Kubernetes와의 완벽한 연동</strong>: 컨테이너를 오케스트레이션하는 것처럼 배치를 오케스트레이션</li>
  <li><strong>Spring Batch와의 완벽한 호환</strong>: 유용한 배치 정보를 시각적으로 모니터링 가능</li>
</ol>

<h1 id="3-kubernetes와의-연동을-통한-자원-관리-최적화">3. Kubernetes와의 연동을 통한 자원 관리 최적화</h1>

<p><strong>Spring Cloud Data Flow</strong>를 <strong>Kubernetes</strong>와 연동하면 다음과 같은 이점이 있습니다:</p>

<h2 id="3-1-배치-오케스트레이션의-장점">3-1. 배치 오케스트레이션의 장점</h2>

<ul>
  <li><strong>독립적인 실행</strong>: 다수의 배치가 상호 간섭 없이 실행 가능</li>
  <li><strong>리소스 컨트롤</strong>: Kubernetes에서 리소스의 사용과 반납을 조율하여 동시에 많은 배치가 실행되더라도 안정적인 자원 관리 가능</li>
  <li><strong>스케일링</strong>: 필요에 따라 배치 작업의 자원을 동적으로 조정 가능</li>
</ul>

<h2 id="3-2-scdf와-kubernetes의-통합-기능">3-2. SCDF와 Kubernetes의 통합 기능</h2>

<p><strong>Spring Cloud Data Flow</strong>와 <strong>Kubernetes</strong>의 통합은 다음과 같은 기능을 제공합니다:</p>

<ol>
  <li><strong>스케줄 관리</strong>: Kubernetes의 CronJob을 활용한 스케줄 관리</li>
  <li><strong>애플리케이션 실행 및 배포</strong>: Kubernetes 요청을 통한 애플리케이션 실행 및 배포</li>
  <li><strong>워크플로우 관리</strong>: 배치 실행 순서를 그래프 형태로 설정 가능</li>
  <li><strong>자원 설정</strong>: CPU, 메모리 등 자원 할당 조정 가능
    <ul>
      <li>데이터 처리량이 많거나 멀티스레드 작업이 필요한 경우 더 많은 자원 할당 가능</li>
    </ul>
  </li>
  <li><strong>모니터링</strong>:
    <ul>
      <li>애플리케이션 로그 제공</li>
      <li>Pod 상태 모니터링</li>
      <li>배치 상태 및 결과 모니터링</li>
    </ul>
  </li>
</ol>

<h2 id="3-3-그래프-기반-태스크-생성">3-3. 그래프 기반 태스크 생성</h2>

<p><strong>SCDF</strong>는 여러 배치를 그래프 형태로 묶고, 실행 결과에 따라 다음 실행할 배치를 조건부로 결정할 수 있습니다.</p>

<p>예를 들어:</p>

<ul>
  <li>배치 상태가 <code class="language-plaintext highlighter-rouge">FAILED</code>인 경우 → Task A 실행</li>
  <li>배치 상태가 <code class="language-plaintext highlighter-rouge">COMPLETED</code>인 경우 → Task B 실행</li>
</ul>

<p>이러한 방식으로 <strong>복잡한 배치 워크플로우를 직관적으로 설계하고 관리</strong>할 수 있습니다.</p>

<h1 id="4-배치-모니터링과-성능-분석">4. 배치 모니터링과 성능 분석</h1>

<p>효과적인 배치 작업 관리를 위해서는 모니터링과 성능 분석이 필수적입니다. SCDF는 Spring Batch와의 강력한 호환성을 바탕으로 풍부한 모니터링 기능을 제공합니다.</p>

<h2 id="4-1-scdf의-배치-모니터링-기능">4-1. SCDF의 배치 모니터링 기능</h2>

<p>SCDF는 Spring Batch와의 호환성을 통해 다음과 같은 상세한 정보를 대시보드로 제공합니다:</p>

<ol>
  <li><strong>배치 실행 상태</strong>: 전체 배치 작업의 상태와 진행 상황</li>
  <li><strong>스텝 상세 정보</strong>: 각 스텝별 정보
    <ul>
      <li>읽은 아이템 개수</li>
      <li>쓴 아이템 개수</li>
      <li>커밋 개수</li>
      <li>롤백 개수</li>
      <li>수행 시간</li>
      <li>최종 상태</li>
    </ul>
  </li>
</ol>

<p>하나의 배치가 10개의 스텝으로 구성되어 있다고 가정할 때, 각 스텝별로 소요된 시간과 같은 상세한 정보를 볼 수 있습니다. 예를 들어, 특정 스텝이 100만 개의 데이터를 읽고 쓰는데 3분 35초가 소요되었다는 정보를 시각적으로 확인할 수 있습니다.</p>

<h2 id="4-2-스텝-누적-히스토리">4-2. 스텝 누적 히스토리</h2>

<p>SCDF는 각 스텝의 누적 히스토리도 제공합니다:</p>

<ul>
  <li>전체 소요 시간</li>
  <li>한 번 읽을 때 소요 시간</li>
  <li>읽기 횟수</li>
  <li>쓰기 횟수</li>
</ul>

<p>이러한 정보는 <strong>최소, 최대, 평균, 표준편차 값으로 제공되어 배치 성능을 분석하는 데 도움</strong>이 됩니다.</p>

<h2 id="4-3-prometheus와-연동하여-메트릭-수집">4-3. Prometheus와 연동하여 메트릭 수집</h2>

<p>Prometheus는 시계열 데이터베이스로서, 애플리케이션에서 발생하는 다양한 메트릭을 수집하고 저장합니다. SCDF에서 실행한 배치 작업들에 대하여 Prometheus에 메트릭을 전송하고, 수집된 메트릭을 시각화하여 분석하기 위해 Grafana 대시보드를 구축할 수 있습니다.</p>

<h1 id="결론">결론</h1>
<p><strong>Spring Cloud Data Flow</strong>와 <strong>Kubernetes</strong>를 활용하면 효율적이고 확장 가능한 배치 구동 환경을 구축할 수 있습니다. 이러한 환경은 다음과 같은 장점을 제공합니다:</p>

<ol>
  <li><strong>효과적인 자원 관리</strong>: Kubernetes를 통한 동적 자원 할당과 회수</li>
  <li><strong>직관적인 배치 워크플로우 관리</strong>: 그래프 기반의 시각적 워크플로우 설계</li>
  <li><strong>상세한 모니터링</strong>: Spring Batch 및 SCDF와의 호환성을 통한 풍부한 모니터링 정보</li>
</ol>

<p><strong>Spring Cloud Data Flow</strong>의 시각적 인터페이스와 <strong>Kubernetes</strong>의 강력한 오케스트레이션 기능을 결합하여 효율적인 배치 시스템을 구축할 수 있었습니다.</p>

<h1 id="참고-자료">참고 자료</h1>

<ul>
  <li><a href="https://dataflow.spring.io/docs/installation/kubernetes/">Spring Cloud Data Flow on Kubernetes</a></li>
  <li><a href="https://prometheus.io/docs/introduction/overview/" target="_blank">Prometheus Documentation</a></li>
  <li><a href="https://grafana.com/docs/">Grafana Documentation</a></li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="Spring Batch" /><category term="Spring Cloud Data Flow" /><category term="Kubernetes" /><category term="Spring Batch" /><category term="Spring Cloud Data Flow" /><category term="Kubernetes" /><summary type="html"><![CDATA[Spring Cloud Data Flow와 Kuebernetes 연동하여 효과적인 배치 구동 환경에 대해 알아봅시다!]]></summary></entry><entry><title type="html">Spring Batch 효율적인 대량 데이터 Write 전략</title><link href="http://localhost:4000/spring%20batch/2025/03/23/Spring-Batch-Optimized-Write/" rel="alternate" type="text/html" title="Spring Batch 효율적인 대량 데이터 Write 전략" /><published>2025-03-23T00:00:00+09:00</published><updated>2025-03-23T00:00:00+09:00</updated><id>http://localhost:4000/spring%20batch/2025/03/23/Spring-Batch-Optimized-Write</id><content type="html" xml:base="http://localhost:4000/spring%20batch/2025/03/23/Spring-Batch-Optimized-Write/"><![CDATA[<blockquote>
  <p>스프링 배치 환경에서 <strong>JPA 기반</strong> <code class="language-plaintext highlighter-rouge">ItemWriter</code>의 성능 저하 요인을 분석하고, <strong>JDBC 배치 인서트 전략</strong>을 통한 성능 개선 방안을 알아봅니다.</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">🚀 들어가기</h1>

<p>대용량 데이터 처리는 엔터프라이즈 애플리케이션에서 흔히 마주하는 도전 과제입니다. 특히 <strong>Spring Batch</strong> 환경에서 대량의 데이터를 효율적으로 저장하는 것은 전체 배치 프로세스의 성능에 직접적인 영향을 미칩니다. 본 포스트에서는 <strong>JPA 기반</strong> <code class="language-plaintext highlighter-rouge">ItemWriter</code> 사용 시 발생하는 성능 제약 요인을 상세히 분석하고, <strong>JDBC 기반 배치 인서트</strong>를 활용한 성능 최적화 전략에 대해 살펴보겠습니다.</p>

<h1 id="jpa-기반-itemwriter의-성능-제약-요인">JPA 기반 ItemWriter의 성능 제약 요인</h1>

<p>먼저 배치 처리 환경에서 JPA의 적합성에 대해 고민해볼 필요가 있습니다. JPA는 <strong>영속성 컨텍스트</strong>를 통해 개발자에게 많은 <strong>편의성을 제공</strong>하지만, 이러한 추상화 계층은 내부적으로 복잡한 로직을 수행하며 대량 데이터 처리 시 <strong>성능 오버헤드</strong>로 작용할 수 있습니다.</p>

<h1 id="영속성-컨텍스트와-더티-체킹-오버헤드">영속성 컨텍스트와 더티 체킹 오버헤드</h1>

<p><strong>JPA</strong>는 정교한 <strong>ORM 프레임워크</strong>로서 엔티티의 상태 변화를 감지하고 관리하기 위해 <strong>영속성 컨텍스트</strong>와 <strong>더티 체킹(Dirty Checking) 메커니즘</strong>을 활용합니다. 이 과정에서 다음과 같은 오버헤드가 발생합니다:</p>

<ol>
  <li><strong>엔티티 상태 추적</strong>: 모든 엔티티의 원본 상태를 메모리에 유지하고 변경사항을 감지</li>
  <li><strong>스냅샷 비교</strong>: 트랜잭션 커밋 시점에 원본 스냅샷과 현재 상태를 비교하는 연산 수행</li>
  <li><strong>캐시 관리</strong>: 1차 캐시와 2차 캐시의 동기화 및 관리 비용</li>
</ol>

<p><strong>배치 처리</strong>에서는 일반적으로 <strong>데이터의 읽기와 쓰기 단계가 명확히 구분</strong>되어 있어, 이러한 정교한 <strong>상태 관리 메커니즘이 불필요한 오버헤드로 작용</strong>할 수 있습니다.</p>

<h1 id="불필요한-컬럼-업데이트-문제">불필요한 컬럼 업데이트 문제</h1>

<p>JPA는 기본적으로 변경 감지 시 엔티티의 모든 필드를 포함한 <code class="language-plaintext highlighter-rouge">UPDATE</code> 쿼리를 생성합니다. 이는 다음과 같은 문제를 야기합니다:</p>

<ol>
  <li><strong>비효율적인 SQL 생성</strong>: 실제로 변경된 필드만 업데이트하는 것이 아니라 모든 필드를 포함한 SQL 생성</li>
  <li><strong>데이터베이스 부하 증가</strong>: 불필요한 컬럼까지 업데이트함으로써 데이터베이스 리소스 낭비</li>
  <li><strong>최적화 제한</strong>: 특정 컬럼만 선택적으로 업데이트하는 최적화 전략 적용 어려움</li>
</ol>

<p>이러한 <strong>JPA의 특성</strong>은 대규모 배치 처리 환경에서 심각한 <strong>성능 병목</strong> 현상을 초래할 수 있습니다.</p>

<p>아래는 스프링 배치에서 <strong>JPA 기반의</strong> <code class="language-plaintext highlighter-rouge">ItemWriter</code>를 사용하는 일반적인 코드입니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">JpaItemWriter</span><span class="o">&lt;</span><span class="nc">DailySettlement</span><span class="o">&gt;</span> <span class="nf">aggregateDailySettlementWriter</span><span class="o">()</span> <span class="o">{</span>
    <span class="nc">JpaItemWriter</span><span class="o">&lt;</span><span class="nc">DailySettlement</span><span class="o">&gt;</span> <span class="n">writer</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">JpaItemWriter</span><span class="o">&lt;&gt;();</span>
    <span class="n">writer</span><span class="o">.</span><span class="na">setEntityManagerFactory</span><span class="o">(</span><span class="n">entityManagerFactory</span><span class="o">);</span>
    <span class="k">return</span> <span class="n">writer</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>이 코드는 <strong>간결하고 직관적</strong>이지만, 내부적으로는 <strong>영속성 컨텍스트 관리, 변경 감지, 그리고 각 엔티티별 개별 업데이트라는 오버헤드</strong>를 수반합니다.</p>

<figure align="center">
<img src="/post_images/spring-batch-optimization/jpa-overhead-diagram.svg" />
<figcaption></figcaption>
</figure>

<h1 id="jdbc-배치-인서트를-통한-성능-최적화">JDBC 배치 인서트를 통한 성능 최적화</h1>

<p><strong>JDBC 배치 인서트</strong>는 여러 SQL 명령을 그룹화하여 <strong>단일 네트워크 요청</strong>으로 데이터베이스에 전송하는 기법입니다. 이 방식은 다음과 같은 이점을 제공합니다:</p>

<ol>
  <li><strong>네트워크 오버헤드 감소</strong>: 여러 쿼리를 하나의 요청으로 묶어 네트워크 왕복 시간 최소화</li>
  <li><strong>데이터베이스 최적화</strong>: 데이터베이스가 여러 연산을 일괄 처리하여 내부 최적화 적용 가능</li>
  <li><strong>리소스 효율성</strong>: 커넥션 관리 및 트랜잭션 오버헤드 감소</li>
</ol>

<p>다음은 사이드 프로젝트에서 일일 정산 집계 데이터를 업데이트 하기 위해 <strong>JDBC 배치 인서트</strong>를 활용한 최적화된 <code class="language-plaintext highlighter-rouge">ItemWriter</code> 구현 예시입니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">ItemWriter</span><span class="o">&lt;</span><span class="nc">SettlementAggregationResult</span><span class="o">&gt;</span> <span class="nf">optimizedAggregateDailySettlementJdbcWriter</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">new</span> <span class="nc">ItemWriter</span><span class="o">&lt;</span><span class="nc">SettlementAggregationResult</span><span class="o">&gt;()</span> <span class="o">{</span>
        <span class="nd">@Autowired</span>
        <span class="kd">private</span> <span class="nc">JdbcTemplate</span> <span class="n">jdbcTemplate</span><span class="o">;</span>

        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="nc">Chunk</span><span class="o">&lt;?</span> <span class="kd">extends</span> <span class="nc">SettlementAggregationResult</span><span class="o">&gt;</span> <span class="n">items</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Exception</span> <span class="o">{</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">items</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
                <span class="k">return</span><span class="o">;</span>
            <span class="o">}</span>

            <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Processing {} settlement aggregation results with JDBC batch update"</span><span class="o">,</span> <span class="n">items</span><span class="o">.</span><span class="na">size</span><span class="o">());</span>

            <span class="nc">String</span> <span class="n">updateSql</span> <span class="o">=</span> <span class="s">"""
                        UPDATE daily_settlement SET
                            total_order_count = ?,
                            total_claim_count = ?,
                            total_quantity = ?,
                            sales_amount = ?,
                            tax_amount = ?,
                            promotion_discount_amount = ?,
                            coupon_discount_amount = ?,
                            point_used_amount = ?,
                            shipping_fee = ?,
                            claim_shipping_fee = ?,
                            commission_amount = ?,
                            total_settlement_amount = ?,
                            updated_at = ?
                        WHERE settlement_id = ?
                    """</span><span class="o">;</span>

            <span class="n">jdbcTemplate</span><span class="o">.</span><span class="na">batchUpdate</span><span class="o">(</span><span class="n">updateSql</span><span class="o">,</span> <span class="k">new</span> <span class="nc">BatchPreparedStatementSetter</span><span class="o">()</span> <span class="o">{</span>
                <span class="nd">@Override</span>
                <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setValues</span><span class="o">(</span><span class="nc">PreparedStatement</span> <span class="n">ps</span><span class="o">,</span> <span class="kt">int</span> <span class="n">i</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">SQLException</span> <span class="o">{</span>
                    <span class="nc">SettlementAggregationResult</span> <span class="n">result</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="na">getItems</span><span class="o">().</span><span class="na">get</span><span class="o">(</span><span class="n">i</span><span class="o">);</span>
                    <span class="nc">LocalDateTime</span> <span class="n">now</span> <span class="o">=</span> <span class="nc">LocalDateTime</span><span class="o">.</span><span class="na">now</span><span class="o">();</span>
                    <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span>

                    <span class="c1">// SET clause parameters</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setInt</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalOrderCount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setInt</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalClaimCount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setInt</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalQuantity</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalSalesAmount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalTaxAmount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalPromotionDiscountAmount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalCouponDiscountAmount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalPointUsedAmount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalShippingFee</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalClaimShippingFee</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalCommissionAmount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setBigDecimal</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalSettlementAmount</span><span class="o">());</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setTimestamp</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="nc">Timestamp</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">now</span><span class="o">));</span>

                    <span class="c1">// WHERE clause parameter</span>
                    <span class="n">ps</span><span class="o">.</span><span class="na">setLong</span><span class="o">(</span><span class="n">idx</span><span class="o">++,</span> <span class="n">result</span><span class="o">.</span><span class="na">getSettlementId</span><span class="o">());</span>
                <span class="o">}</span>

                <span class="nd">@Override</span>
                <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getBatchSize</span><span class="o">()</span> <span class="o">{</span>
                    <span class="k">return</span> <span class="n">items</span><span class="o">.</span><span class="na">size</span><span class="o">();</span>
                <span class="o">}</span>
            <span class="o">});</span>

            <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Successfully updated {} daily settlements with batch update"</span><span class="o">,</span> <span class="n">items</span><span class="o">.</span><span class="na">size</span><span class="o">());</span>
        <span class="o">}</span>
    <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<p>이 구현에서는 <strong>JPA의 불필요한 오버헤드를 제거</strong>하고, 주어진 청크 내의 모든 항목을 단일 배치 연산으로 처리함으로써 <strong>네트워크 왕복 시간을 크게 감소</strong>시킵니다.</p>

<h1 id="id-생성-전략과-jpa-배치-인서트-제약">ID 생성 전략과 JPA 배치 인서트 제약</h1>

<p><strong>JPA</strong>에서도 <code class="language-plaintext highlighter-rouge">hibernate.jdbc.batch_size</code> 속성을 통해 배치 인서트를 지원하지만, <strong>ID 생성 전략</strong>에 따라 중요한 <strong>제약</strong>이 존재합니다:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">IDENTITY</code> <strong>전략 제약</strong>:
    <ul>
      <li>IDENTITY 전략을 사용할 경우 Hibernate는 배치 인서트를 비활성화합니다.</li>
      <li>이는 데이터베이스가 자동 증가 ID 값을 생성하고, Hibernate는 이 값을 즉시 조회해야 하기 때문입니다.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">SEQUENCE</code> <strong>전략 활용</strong>:
    <ul>
      <li>SEQUENCE 전략을 사용하면 Hibernate가 사전에 ID 값을 할당하여 배치 인서트를 수행할 수 있습니다.</li>
      <li><code class="language-plaintext highlighter-rouge">SEQUENCE</code> 전략은 Hibernate가 미리 여러 개의 ID 값을 가져올 수 있습니다(<code class="language-plaintext highlighter-rouge">allocationSize</code> 활용).</li>
      <li>즉, Hibernate는 ID 값을 미리 할당한 후, 여러 개의 <code class="language-plaintext highlighter-rouge">INSERT</code> 문을 한 번의 JDBC batch로 실행할 수 있습니다.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">TABLE</code> <strong>전략 오버헤드</strong>:
    <ul>
      <li>TABLE 전략은 별도의 테이블을 사용하여 ID를 생성하는 방식이며, 배치 인서트 자체는 가능하지만 시퀀스 테이블에 대한 동시 접근으로 인해 <strong>잠금 경합(lock contention)</strong>이 발생할 가능성이 높습니다.</li>
      <li>따라서 대량 삽입 작업 시 성능 저하가 발생할 수 있습니다.</li>
    </ul>
  </li>
</ol>

<p>실무 환경에서는 종종 데이터베이스의 자동 증가 기능에 의존하는 <code class="language-plaintext highlighter-rouge">IDENTITY</code> 전략을 사용하기 때문에, JPA의 배치 인서트 기능을 활용하기에 현실적으로 어려운 경우가 많습니다. 이런 상황에서는 <strong>순수 JDBC</strong>를 직접 사용하는 배치 인서트가 효과적인 대안이 될 것입니다.</p>

<h1 id="추가-개선-방안">추가 개선 방안</h1>

<p><strong>JDBC</strong> 방식을 활용하면서 발생할 수 있는 <strong>SQL문의 타입 안전성 부재</strong>와 <strong>유지보수성 저하 문제</strong>를 해결하기 위해 다음과 같은 개선 방안을 고려할 수 있습니다:</p>

<h2 id="querydsl-도입">QueryDSL 도입</h2>

<p><strong>QueryDSL</strong>을 활용하면 타입 안전한 방식으로 SQL 쿼리를 작성하면서도 배치 인서트의 성능 이점을 유지할 수 있습니다.</p>

<p>아래 코드는 QueryDSL을 적용한 예시 코드입니다. 기존 문자열로 SQL를 다룰 때보다 깔끔하고, 컴파일 시점에 오류를 잡아낼 수 있어서 안정적입니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">ItemWriter</span><span class="o">&lt;</span><span class="nc">SettlementAggregationResult</span><span class="o">&gt;</span> <span class="nf">querydslBatchWriter</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">new</span> <span class="nc">ItemWriter</span><span class="o">&lt;</span><span class="nc">SettlementAggregationResult</span><span class="o">&gt;()</span> <span class="o">{</span>
        <span class="nd">@Autowired</span>
        <span class="kd">private</span> <span class="nc">SQLQueryFactory</span> <span class="n">queryFactory</span><span class="o">;</span>
        
        <span class="nd">@Override</span>
        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="nc">Chunk</span><span class="o">&lt;?</span> <span class="kd">extends</span> <span class="nc">SettlementAggregationResult</span><span class="o">&gt;</span> <span class="n">items</span><span class="o">)</span> <span class="o">{</span>
            <span class="c1">// QueryDSL을 사용한 배치 업데이트 구현</span>
            <span class="nc">List</span><span class="o">&lt;</span><span class="nc">SQLInsertBatch</span><span class="o">&gt;</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="na">getItems</span><span class="o">().</span><span class="na">stream</span><span class="o">()</span>
                <span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">this</span><span class="o">::</span><span class="n">createBatchUpdate</span><span class="o">)</span>
                <span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="nc">Collectors</span><span class="o">.</span><span class="na">toList</span><span class="o">());</span>
                
            <span class="n">queryFactory</span><span class="o">.</span><span class="na">batch</span><span class="o">(</span><span class="n">batch</span><span class="o">.</span><span class="na">toArray</span><span class="o">(</span><span class="k">new</span> <span class="nc">SQLInsertBatch</span><span class="o">[</span><span class="mi">0</span><span class="o">])).</span><span class="na">execute</span><span class="o">();</span>
        <span class="o">}</span>
        
        <span class="kd">private</span> <span class="nc">SQLInsertBatch</span> <span class="nf">createBatchUpdate</span><span class="o">(</span><span class="nc">SettlementAggregationResult</span> <span class="n">result</span><span class="o">)</span> <span class="o">{</span>
            <span class="c1">// 타입 안전한 업데이트 구문 작성</span>
            <span class="nc">QDailySettlement</span> <span class="n">settlement</span> <span class="o">=</span> <span class="nc">QDailySettlement</span><span class="o">.</span><span class="na">dailySettlement</span><span class="o">;</span>
            <span class="k">return</span> <span class="n">queryFactory</span><span class="o">.</span><span class="na">update</span><span class="o">(</span><span class="n">settlement</span><span class="o">)</span>
                <span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">settlement</span><span class="o">.</span><span class="na">totalOrderCount</span><span class="o">,</span> <span class="n">result</span><span class="o">.</span><span class="na">getTotalOrderCount</span><span class="o">())</span>
                <span class="c1">// 기타 필드 설정</span>
                <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="n">settlement</span><span class="o">.</span><span class="na">settlementId</span><span class="o">.</span><span class="na">eq</span><span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="na">getSettlementId</span><span class="o">()));</span>
        <span class="o">}</span>
    <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<h1 id="성능-모니터링-및-최적화---앞으로의-계획">성능 모니터링 및 최적화 - 앞으로의 계획</h1>

<p>현재 사이드 프로젝트에서는 기본적인 배치 인서트 구현에 집중하고 있지만, 향후 성능을 더욱 개선하기 위해 다음과 같은 추가 전략을 적용할 계획입니다:</p>

<ol>
  <li><strong>청크 크기 최적화</strong>: 메모리 사용량과 처리 속도의 균형을 고려한 최적의 청크 크기를 찾는 실험을 진행할 예정입니다. 현재는 고정값(size: 1000)을 사용 중이지만, 실제 데이터 특성에 맞는 최적화가 필요합니다.</li>
  <li><strong>실행 계획 분석</strong>: 배치 처리 시 생성되는 SQL의 실행 계획을 분석하여 인덱스 활용을 최적화하는 작업도 진행하면 좋을 것 같습니다. 현재는 기본 인덱스만 활용 중이지만, 실행 패턴에 따른, 좀 더 세밀한 인덱스 전략이 필요해 보입니다.</li>
  <li>
    <p><strong>Rewrite 배치 전략</strong>: 대량 데이터 갱신 시 임시 테이블을 활용한 Rewrite 전략도 검토 중입니다. 이 전략은 다음과 같은 이유로 특히 대규모 업데이트가 필요한 월별 정산 처리에서 효과적일 것으로 예상됩니다:</p>

    <ul>
      <li><strong>테이블 잠금 최소화</strong>: 개별 UPDATE 문은 해당 레코드에 대한 잠금을 발생시켜 동시성을 저하시킬 수 있지만, 임시 테이블에 데이터를 먼저 준비한 후 한 번에 교체하면 잠금 시간을 최소화할 수 있습니다.</li>
      <li><strong>트랜잭션 로그 감소</strong>: 수많은 개별 UPDATE 문은 대량의 트랜잭션 로그를 생성하지만, INSERT-SELECT 또는 MERGE 패턴을 사용하면 로그량을 크게 줄일 수 있습니다.</li>
      <li><strong>인덱스 부하 감소</strong>: 반복적인 UPDATE는 인덱스 재구성 부하를 지속적으로 발생시키지만, 임시 테이블 방식은 인덱스 유지 비용을 일괄 처리할 수 있습니다.</li>
      <li><strong>I/O 패턴 최적화</strong>: 순차적 I/O는 랜덤 I/O보다 훨씬 효율적인데, 임시 테이블을 생성하고 대량 데이터를 삽입하는 경우는 주로 순차적 I/O 패턴을 따르게 됩니다.</li>
    </ul>
  </li>
</ol>

<p>이러한 고급 최적화 전략들은 현재 기본 구현을 완료한 후 성능 테스트를 통해 점진적으로 도입할 예정입니다. 실제 적용 결과와 성능 개선 지표는 후속 포스팅에서 공유하겠습니다.</p>

<h1 id="결론">결론</h1>

<p><strong>Spring Batch</strong> 환경에서 대용량 데이터를 효율적으로 처리하기 위해서는 사용 사례에 적합한 기술을 선택하는 것이 중요합니다. <strong>JPA</strong>는 개발 생산성과 객체 지향적 접근을 제공하지만, 대량 데이터 처리 시에는 성능 제약이 존재합니다. 반면 <strong>JDBC 배치 인서트</strong>는 로우 레벨 접근을 통해 최적의 성능을 제공하지만 타입 안전성과 유지보수성 측면에서 추가적인 노력이 필요합니다.</p>

<p>실무에서는 이러한 <strong>트레이드오프</strong>를 충분히 이해하고, 처리해야 할 <strong>데이터의 볼륨과 성능 요구사항에 따라 적절한 전략을 선택</strong>해야 합니다. 특히 대규모 데이터 처리가 필요한 배치 작업에서는 <strong>JDBC 배치 인서트</strong>와 같은 최적화 기법을 적극적으로 활용하되, <strong>QueryDSL</strong>과 같은 도구를 함께 도입하여 <strong>유지보수성</strong>도 함께 확보하는 것이 좋을 것 같습니다.</p>

<h1 id="마무리">마무리</h1>

<p>본 포스트가 Spring Batch 환경에서 대용량 데이터 처리 시 발생할 수 있는 성능 병목 현상을 이해하고, 실질적인 최적화 전략을 수립하는 데 도움이 되었으면 좋겠습니다. 해당 사이드 프로젝트를 진행하면서 기술적 편의성과 성능 사이의 균형을 찾는 과정이 엔지니어링의 핵심이라는 것을 다시 한 번 느낄 수 있었습니다. 앞으로도 실무에서 얻은 경험과 학습을 통해 더 나은 기술적 해결책을 모색하고 공유하겠습니다.</p>

<p>감사합니다.</p>

<h1 id="참고-자료">참고 자료</h1>

<ul>
  <li><a href="https://docs.jboss.org/hibernate/orm/6.6/introduction/html_single/Hibernate_Introduction.html#statement-batching" target="_blank">Hibernate - Enabling statement batching</a></li>
  <li><a href="https://www.baeldung.com/jpa-hibernate-batch-insert-update" target="_blank">Batch Insert/Update with Hibernate/JPA</a></li>
  <li><a href="https://docs.spring.io/spring-framework/reference/data-access/jdbc/advanced.html#jdbc-batch-classic" target="_blank">Basic Batch Operations with JdbcTemplate</a></li>
  <li><a href="https://docs.oracle.com/cd/E19455-01/806-3204/6jccb3gac/index.html" target="_blank">Optimizing for Random I/O and Sequential I/O</a></li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="Spring Batch" /><category term="Spring Batch" /><category term="JPA" /><category term="JDBC" /><category term="Batch Insert" /><summary type="html"><![CDATA[스프링 배치 환경에서 JPA 기반 ItemWriter의 성능 저하 요인을 분석하고, JDBC 배치 인서트 전략을 통한 성능 개선 방안을 알아봅니다.]]></summary></entry><entry><title type="html">Spring Batch 데이터 집계(Aggregation) 최적화</title><link href="http://localhost:4000/spring%20batch/2025/03/23/Spring-Batch-Optimized-aggregation/" rel="alternate" type="text/html" title="Spring Batch 데이터 집계(Aggregation) 최적화" /><published>2025-03-23T00:00:00+09:00</published><updated>2025-03-23T00:00:00+09:00</updated><id>http://localhost:4000/spring%20batch/2025/03/23/Spring-Batch-Optimized-aggregation</id><content type="html" xml:base="http://localhost:4000/spring%20batch/2025/03/23/Spring-Batch-Optimized-aggregation/"><![CDATA[<blockquote>
  <p>데이터 집계를 위한 배치 처리 시 <code class="language-plaintext highlighter-rouge">GROUP BY</code>와 <code class="language-plaintext highlighter-rouge">SUM</code> 대신 <strong>Redis</strong>를 활용하여 성능을 대폭 개선할 수 있는 방법에 대해 알아봅시다!</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">🚀 들어가기</h1>

<p>대용량 데이터의 집계 처리는 배치 애플리케이션에서 자주 발생하는 작업이지만, 처리해야 할 데이터 양이 증가할수록 성능 이슈가 발생합니다. 본 포스트에서는 기존 <code class="language-plaintext highlighter-rouge">GROUP BY</code>, <code class="language-plaintext highlighter-rouge">SUM</code> 등 SQL 기반 집계 대신 <strong>Redis</strong>를 활용한 고성능 집계 방법과 그 최적화 과정에 대해 단계별로 알아보겠습니다.</p>

<h1 id="기존-group-by-sum-쿼리의-한계">기존 GROUP BY, SUM 쿼리의 한계</h1>

<p>통계 처리 시 일반적으로 <code class="language-plaintext highlighter-rouge">GROUP BY</code>, <code class="language-plaintext highlighter-rouge">SUM</code> 쿼리를 사용하는 것은 데이터가 적을 때는 효율적입니다. 그러나 데이터가 대용량으로 증가하고 쿼리가 복잡해질수록 여러 성능 문제가 발생합니다:</p>

<ul>
  <li>여러 테이블을 <code class="language-plaintext highlighter-rouge">JOIN</code>하고 <code class="language-plaintext highlighter-rouge">GROUP BY</code>하는 복잡한 쿼리는 데이터베이스 옵티마이저가 비효율적인 실행 계획을 생성할 수 있습니다.</li>
  <li>대량의 데이터 처리 과정에서 임시 테이블 생성으로 인한 디스크 I/O 부하가 증가합니다.</li>
  <li>데이터 양이 증가할수록 쿼리 실행 시간이 기하급수적으로 증가합니다.</li>
  <li>쿼리 튜닝이 복잡해지고 데이터베이스 리소스 사용량이 급증합니다.</li>
</ul>

<p>아래 코드는 배치 과정에서 정산 데이터를 집계하기 위해 <code class="language-plaintext highlighter-rouge">GROUP BY</code>, <code class="language-plaintext highlighter-rouge">SUM</code>을 사용한 SQL문 입니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">String</span> <span class="n">sql</span> <span class="o">=</span> <span class="s">"""
            SELECT
                    ds.settlement_id,
                    ds.seller_id,
                    ds.settlement_date,
                    SUM(IF(dsd.settlement_status = 'COMPLETED', 1, 0)) AS total_order_count,
                    SUM(IF(dsd.settlement_status = 'REFUNDED', 1, 0)) AS total_claim_count,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.quantity
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.quantity
                            ELSE 0
                        END) AS total_quantity,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.sales_amount
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.sales_amount
                            ELSE 0
                        END) AS total_sales_amount,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.tax_amount
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.tax_amount
                            ELSE 0
                        END) AS total_tax_amount,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.promotion_discount_amount
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.promotion_discount_amount
                            ELSE 0
                        END) AS total_promotion_discount_amount,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.coupon_discount_amount
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.coupon_discount_amount
                            ELSE 0
                        END) AS total_coupon_discount_amount,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.point_used_amount
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.point_used_amount
                            ELSE 0
                        END) AS total_point_used_amount,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.shipping_fee
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.shipping_fee
                            ELSE 0
                        END) AS total_shipping_fee,
                    SUM(IF(dsd.settlement_status = 'REFUNDED', dsd.claim_shipping_fee, 0)) AS total_claim_shipping_fee,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.commission_amount
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.commission_amount
                            ELSE 0
                        END) AS total_commission_amount,
                    SUM(CASE
                            WHEN dsd.settlement_status = 'COMPLETED' THEN dsd.settlement_amount
                            WHEN dsd.settlement_status = 'REFUNDED' THEN -dsd.settlement_amount
                            ELSE 0
                        END) AS total_settlement_amount
            FROM daily_settlement_detail dsd
            JOIN daily_settlement ds on dsd.daily_settlement_id = ds.settlement_id
            WHERE ds.settlement_date = ?
            GROUP BY ds.settlement_id, ds.seller_id, ds.settlement_date
        """</span><span class="o">;</span>

</code></pre></div></div>

<h1 id="redis를-활용한-효율적인-집계-처리">Redis를 활용한 효율적인 집계 처리</h1>

<p>대용량 데이터 집계 시 발생하는 <code class="language-plaintext highlighter-rouge">GROUP BY</code> 쿼리의 문제를 해결하기 위해 집계 연산을 <strong>디스크 기반 RDB 데이터베이스</strong>가 아닌 <strong>인메모리 데이터베이스인 Redis</strong>로 이관할 수 있습니다.</p>

<p><strong>Redis</strong>를 집계 처리에 활용하면 다음과 같은 장점이 있습니다:</p>

<ol>
  <li>집계에 최적화된 연산 API 지원 (<code class="language-plaintext highlighter-rouge">hincrby</code>, <code class="language-plaintext highlighter-rouge">hincrbyfloat</code> 등)</li>
  <li>메모리 기반 처리로 디스크 I/O 병목 현상 제거</li>
  <li>인메모리 데이터베이스의 초고속 연산 처리 능력</li>
</ol>

<p>🚨 <strong>주의사항:</strong></p>

<p><strong>Redis</strong>를 사용하면 집계 연산을 빠르게 처리할 순 있지만, 병목 지점이 될 수 있는 지점이 네트워크 레이턴시입니다. 1,000만 개의 데이터를 합산하기 위해 1,000만 번의 개별 네트워크 요청이 발생한다면, 이로 인한 성능 저하는 피할 수 없습니다. ☠️</p>

<h1 id="redis-pipeline을-통한-네트워크-레이턴시-최소화">Redis Pipeline을 통한 네트워크 레이턴시 최소화</h1>

<p><strong>Redis Pipeline</strong>을 활용하면 수많은 <strong>Redis 명령을 묶어서 한 번의 네트워크 왕복으로 처리</strong>할 수 있습니다. 이를 통해 <strong>1,000만 번의 개별 네트워크 요청</strong>을 청크 단위로 묶어 <strong>1만 번</strong> 정도로 줄이면 집계 처리 시간을 획기적으로 단축할 수 있습니다.</p>

<h2 id="개별-요청-방식">개별 요청 방식</h2>

<figure align="center">
<img src="/post_images/spring-batch-optimization/redis-latency1.png" />
<figcaption></figcaption>
</figure>

<h2 id="pipeline-방식">Pipeline 방식</h2>

<figure align="center">
<img src="/post_images/spring-batch-optimization/redis-latency2.png" />
<figcaption></figcaption>
</figure>

<p>💡 <strong>중요한 구현 포인트:</strong></p>

<p><strong>Spring Batch</strong>의 청크 프로세싱 아키텍처를 고려할 때, Redis 파이프라인은 반드시 <code class="language-plaintext highlighter-rouge">ItemWriter</code>에서 생성해야 합니다. Spring Batch는 <code class="language-plaintext highlighter-rouge">ItemReader</code> → <code class="language-plaintext highlighter-rouge">ItemProcessor</code> 단계에서는 항목을 하나씩 처리하다가, 지정된 Chunk 크기만큼 항목이 처리되면 <code class="language-plaintext highlighter-rouge">ItemWriter</code>에게 묶음으로 전달합니다.</p>

<p>만약 <code class="language-plaintext highlighter-rouge">ItemProcessor</code>에서 Redis Pipeline을 생성한다면, 항목마다 Redis 연결을 맺고 끊는 불필요한 오버헤드가 발생합니다. 따라서 <code class="language-plaintext highlighter-rouge">ItemWriter</code>에서 청크 단위로 파이프라인을 처리하는 것이 최적의 구현 방식입니다.</p>

<figure align="center">
<img src="/post_images/spring-batch-optimization/spring-batch-chunk-diagram.svg" />
<figcaption></figcaption>
</figure>

<p>(처음에 청크 프로세싱 아키텍처를 고려하지 않고, 단순히 <code class="language-plaintext highlighter-rouge">ItemProcessor</code>에서 처리하는게 자연스럽단 착각 덕분에 성능이 나빠진 제 경험으로부터 알려드립니다. 😂)</p>

<p>다음은 정산 데이터(<code class="language-plaintext highlighter-rouge">settlement_detail</code>) 청크를 정산 항목별로 <strong>Redis</strong>에서 파이프라인을 사용해 집계 처리하는 코드입니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">ItemWriter</span><span class="o">&lt;</span><span class="nc">SettlementAggregate</span><span class="o">&gt;</span> <span class="nf">optimizedRedisAggregateWriter</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">items</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="c1">// 청크의</span>
        <span class="c1">// 파이프라인 시작</span>
        <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">multi</span><span class="o">();</span>

        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Processing {} items in a single Redis pipeline transaction"</span><span class="o">,</span> <span class="n">items</span><span class="o">.</span><span class="na">size</span><span class="o">());</span>

        <span class="k">for</span> <span class="o">(</span><span class="nc">SettlementAggregate</span> <span class="n">detail</span> <span class="o">:</span> <span class="n">items</span><span class="o">)</span> <span class="o">{</span>
            <span class="nc">String</span> <span class="n">key</span> <span class="o">=</span> <span class="s">"daily_settlement:"</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementId</span><span class="o">();</span>

            <span class="c1">// 상태별 처리</span>
            <span class="k">if</span> <span class="o">(</span><span class="no">COMPLETED</span><span class="o">.</span><span class="na">name</span><span class="o">().</span><span class="na">equals</span><span class="o">(</span><span class="n">detail</span><span class="o">.</span><span class="na">getSettlementStatus</span><span class="o">()))</span> <span class="o">{</span>
                <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrby</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalOrderCount"</span><span class="o">,</span> <span class="mi">1</span><span class="o">);</span>
                <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrby</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalQuantity"</span><span class="o">,</span> <span class="n">detail</span><span class="o">.</span><span class="na">getQuantity</span><span class="o">());</span>
            <span class="o">}</span> <span class="k">else</span> <span class="k">if</span> <span class="o">(</span><span class="no">REFUNDED</span><span class="o">.</span><span class="na">name</span><span class="o">().</span><span class="na">equals</span><span class="o">(</span><span class="n">detail</span><span class="o">.</span><span class="na">getSettlementStatus</span><span class="o">()))</span> <span class="o">{</span>
                <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrby</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalClaimCount"</span><span class="o">,</span> <span class="mi">1</span><span class="o">);</span>
                <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrby</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalQuantity"</span><span class="o">,</span> <span class="o">-</span><span class="n">detail</span><span class="o">.</span><span class="na">getQuantity</span><span class="o">());</span>
            <span class="o">}</span>

            <span class="c1">// 금액 관련 필드 처리</span>
            <span class="nc">String</span> <span class="n">statusMultiplier</span> <span class="o">=</span> <span class="no">REFUNDED</span><span class="o">.</span><span class="na">name</span><span class="o">().</span><span class="na">equals</span><span class="o">(</span><span class="n">detail</span><span class="o">.</span><span class="na">getSettlementStatus</span><span class="o">())</span> <span class="o">?</span> <span class="s">"-"</span> <span class="o">:</span> <span class="s">""</span><span class="o">;</span>

            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalSalesAmount"</span><span class="o">,</span>
                    <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">statusMultiplier</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getSalesAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalTaxAmount"</span><span class="o">,</span>
                    <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">statusMultiplier</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getTaxAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalPromotionDiscountAmount"</span><span class="o">,</span>
                    <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">statusMultiplier</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getPromotionDiscountAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalCouponDiscountAmount"</span><span class="o">,</span>
                    <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">statusMultiplier</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getCouponDiscountAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalPointUsedAmount"</span><span class="o">,</span>
                    <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">statusMultiplier</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getPointUsedAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalShippingFee"</span><span class="o">,</span>
                    <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">statusMultiplier</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getShippingFee</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalCommissionAmount"</span><span class="o">,</span>
                    <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">statusMultiplier</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getCommissionAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalSettlementAmount"</span><span class="o">,</span>
                    <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">statusMultiplier</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>

            <span class="c1">// REFUNDED인 경우 클레임 배송비 추가</span>
            <span class="k">if</span> <span class="o">(</span><span class="no">REFUNDED</span><span class="o">.</span><span class="na">name</span><span class="o">().</span><span class="na">equals</span><span class="o">(</span><span class="n">detail</span><span class="o">.</span><span class="na">getSettlementStatus</span><span class="o">()))</span> <span class="o">{</span>
                <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hincrbyfloat</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"totalClaimShippingFee"</span><span class="o">,</span>
                        <span class="nc">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">detail</span><span class="o">.</span><span class="na">getClaimShippingFee</span><span class="o">().</span><span class="na">toString</span><span class="o">()));</span>
            <span class="o">}</span>

            <span class="c1">// seller_id와 settlement_date 저장 (덮어쓰기 - 모든 레코드가 동일한 값을 가짐)</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hset</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"sellerId"</span><span class="o">,</span> <span class="n">detail</span><span class="o">.</span><span class="na">getSellerId</span><span class="o">().</span><span class="na">toString</span><span class="o">());</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">hset</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="s">"settlementDate"</span><span class="o">,</span> <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementDate</span><span class="o">().</span><span class="na">toString</span><span class="o">());</span>

            <span class="c1">// 해당 settlement에 대한 키 목록에 추가</span>
            <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">sadd</span><span class="o">(</span><span class="s">"settlement_keys:"</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementDate</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span> <span class="n">key</span><span class="o">);</span>
        <span class="o">}</span>

        <span class="c1">// 모든 명령을 한 번에 실행</span>
        <span class="n">redisAsyncCommands</span><span class="o">.</span><span class="na">exec</span><span class="o">();</span>
        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Successfully processed batch of {} settlement details to Redis"</span><span class="o">,</span> <span class="n">items</span><span class="o">.</span><span class="na">size</span><span class="o">());</span>
    <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<p>이 방식을 적용한 후에도 <code class="language-plaintext highlighter-rouge">redisAsyncCommands</code> 클라이언트를 통해 <strong>반복되는 연산 요청을 매번 파이프라인에 적재</strong>해야 하므로, 기존 <code class="language-plaintext highlighter-rouge">GROUP BY</code> 대비 성능 개선이 기대보다 크지 않았습니다.</p>

<p>더 높은 성능 개선을 위해 구글링과 AI에게 조언을 구하여, 저수준 API 활용 방법 중 Lua 스크립트 사용을 고려해 보게 되었습니다.</p>

<h1 id="lua-스크립트를-활용한-집계-처리">Lua 스크립트를 활용한 집계 처리</h1>

<p><strong>파이프라인에 연산 명령어를 적재하는 과정</strong>에서도 여전히 애플리케이션 측에서 <strong>많은 연산</strong> 로직이 필요하다는 사실을 발견했습니다.</p>

<p>(🤔 <code class="language-plaintext highlighter-rouge">StepListener</code>를 활용하여 명령어를 적재하는 과정이 얼마나 시간이 걸리는지 측정했습니다.)</p>

<p>이를 해결하기 위해 <strong>Lua 스크립트</strong>를 활용하여 데이터만 Redis 서버로 전송하고, 모든 집계 연산은 Redis 서버에서 <strong>직접 수행</strong>하도록 개선했습니다.</p>

<p>이 접근 방식의 핵심 장점은 다음과 같습니다:</p>

<ul>
  <li>애플리케이션 측의 연산 오버헤드 제거</li>
  <li>데이터 전송량 최소화</li>
  <li>Redis 서버에서의 원자적 실행 보장</li>
  <li>복잡한 로직을 단일 스크립트로 캡슐화</li>
</ul>

<p>다음은 정산 집계를 위한 Lua 스크립트입니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 집계를 위한 Lua 스크립트</span>
<span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="nc">String</span> <span class="no">AGGREGATE_SCRIPT</span> <span class="o">=</span> <span class="s">"""
        local key = KEYS[1]
        local settlement_key = KEYS[2]
        local status = ARGV[1]
        local seller_id = ARGV[2]
        local settlement_date = ARGV[3]
        local quantity = tonumber(ARGV[4])
        local tax_amount = tonumber(ARGV[5])
        local sales_amount = tonumber(ARGV[6])
        local promotion_discount_amount = tonumber(ARGV[7])
        local coupon_discount_amount = tonumber(ARGV[8])
        local point_used_amount = tonumber(ARGV[9])
        local shipping_fee = tonumber(ARGV[10])
        local claim_shipping_fee = tonumber(ARGV[11])
        local commission_amount = tonumber(ARGV[12])
        local settlement_amount = tonumber(ARGV[13])
        
        if status == 'COMPLETED' then
          redis.call('hincrby', key, 'totalOrderCount', 1)
          redis.call('hincrby', key, 'totalQuantity', quantity)
        else
          redis.call('hincrby', key, 'totalClaimCount', 1)
          redis.call('hincrby', key, 'totalQuantity', -quantity)
        end
        
        local multiplier = status == 'REFUNDED' and -1 or 1
        redis.call('hincrbyfloat', key, 'totalSalesAmount', multiplier * sales_amount)
        redis.call('hincrbyfloat', key, 'totalTaxAmount', multiplier * tax_amount)
        redis.call('hincrbyfloat', key, 'totalPromotionDiscountAmount', multiplier * promotion_discount_amount)
        redis.call('hincrbyfloat', key, 'totalCouponDiscountAmount', multiplier * coupon_discount_amount)
        redis.call('hincrbyfloat', key, 'totalPointUsedAmount', multiplier * point_used_amount)
        redis.call('hincrbyfloat', key, 'totalShippingFee', multiplier * shipping_fee)
        redis.call('hincrbyfloat', key, 'totalCommissionAmount', multiplier * commission_amount)
        redis.call('hincrbyfloat', key, 'totalSettlementAmount', multiplier * settlement_amount)
        
        if status == 'REFUNDED' then
          redis.call('hincrbyfloat', key, 'totalClaimShippingFee', claim_shipping_fee)
        end
        
        redis.call('hset', key, 'sellerId', seller_id)
        redis.call('hset', key, 'settlementDate', settlement_date)
        redis.call('sadd', settlement_key, key)
        
        return 1
        """</span><span class="o">;</span>

</code></pre></div></div>

<p>다음은 <strong>Lua 스크립트</strong>를 활용해 <strong>Redis</strong>에서 집계 연산을 수행하는 <code class="language-plaintext highlighter-rouge">ItemWriter</code> 구현입니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="kd">public</span> <span class="nc">ItemWriter</span><span class="o">&lt;</span><span class="nc">SettlementAggregate</span><span class="o">&gt;</span> <span class="nf">luaScriptDirectWriter</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">items</span> <span class="o">-&gt;</span> <span class="o">{</span>
        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Processing {} items with Redis Lua Script direct execution"</span><span class="o">,</span> <span class="n">items</span><span class="o">.</span><span class="na">size</span><span class="o">());</span>

        <span class="c1">// Lua 스크립트를 활용한 처리</span>
        <span class="k">try</span> <span class="o">(</span><span class="nc">StatefulRedisConnection</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">connection</span> <span class="o">=</span> <span class="n">redisClient</span><span class="o">.</span><span class="na">connect</span><span class="o">())</span> <span class="o">{</span>
            <span class="nc">RedisAsyncCommands</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">async</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="na">async</span><span class="o">();</span>
            <span class="n">async</span><span class="o">.</span><span class="na">setAutoFlushCommands</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

            <span class="nc">List</span><span class="o">&lt;</span><span class="nc">RedisFuture</span><span class="o">&lt;?&gt;&gt;</span> <span class="n">futures</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;&gt;();</span>

            <span class="k">for</span> <span class="o">(</span><span class="nc">SettlementAggregate</span> <span class="n">detail</span> <span class="o">:</span> <span class="n">items</span><span class="o">)</span> <span class="o">{</span>
                <span class="nc">String</span> <span class="n">key</span> <span class="o">=</span> <span class="s">"daily_settlement:"</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementId</span><span class="o">();</span>
                <span class="nc">String</span> <span class="n">settlementKeysKey</span> <span class="o">=</span> <span class="s">"settlement_keys:"</span> <span class="o">+</span> <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementDate</span><span class="o">().</span><span class="na">toString</span><span class="o">();</span>

                <span class="c1">// Lua 스크립트 실행 - 모든 연산을 레디스 서버에서 처리</span>
                <span class="n">futures</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">async</span><span class="o">.</span><span class="na">eval</span><span class="o">(</span>
                        <span class="no">AGGREGATE_SCRIPT</span><span class="o">,</span>
                        <span class="nc">ScriptOutputType</span><span class="o">.</span><span class="na">INTEGER</span><span class="o">,</span>
                        <span class="k">new</span> <span class="nc">String</span><span class="o">[]{</span><span class="n">key</span><span class="o">,</span> <span class="n">settlementKeysKey</span><span class="o">},</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementStatus</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getSellerId</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementDate</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="nc">String</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">detail</span><span class="o">.</span><span class="na">getQuantity</span><span class="o">()),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getTaxAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getSalesAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getPromotionDiscountAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getCouponDiscountAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getPointUsedAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getShippingFee</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getClaimShippingFee</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getCommissionAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">(),</span>
                        <span class="n">detail</span><span class="o">.</span><span class="na">getSettlementAmount</span><span class="o">().</span><span class="na">toString</span><span class="o">()</span>
                <span class="o">));</span>
            <span class="o">}</span>

            <span class="c1">// 모든 명령어 한번에 전송</span>
            <span class="n">async</span><span class="o">.</span><span class="na">flushCommands</span><span class="o">();</span>

            <span class="c1">// 모든 작업 완료 대기</span>
            <span class="nc">CompletableFuture</span><span class="o">.</span><span class="na">allOf</span><span class="o">(</span><span class="n">futures</span><span class="o">.</span><span class="na">toArray</span><span class="o">(</span><span class="k">new</span> <span class="nc">CompletableFuture</span><span class="o">[</span><span class="mi">0</span><span class="o">]))</span>
                    <span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="mi">30</span><span class="o">,</span> <span class="nc">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">log</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="s">"Error processing settlements with Lua script: {}"</span><span class="o">,</span> <span class="n">e</span><span class="o">.</span><span class="na">getMessage</span><span class="o">(),</span> <span class="n">e</span><span class="o">);</span>
            <span class="k">throw</span> <span class="k">new</span> <span class="nf">RuntimeException</span><span class="o">(</span><span class="s">"Error executing Redis Lua script"</span><span class="o">,</span> <span class="n">e</span><span class="o">);</span>
        <span class="o">}</span>

        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Successfully processed batch of {} settlement details to Redis using Lua script"</span><span class="o">,</span> <span class="n">items</span><span class="o">.</span><span class="na">size</span><span class="o">());</span>
    <span class="o">};</span>
<span class="o">}</span>
</code></pre></div></div>

<h1 id="lua-스크립트-사용-시-주의사항과-트레이드-오프">Lua 스크립트 사용 시 주의사항과 트레이드 오프</h1>

<p><strong>Lua 스크립트</strong>를 통한 최적화는 큰 성능 향상을 가져올 수 있지만, 몇 가지 중요한 고려사항과 <strong>트레이드 오프</strong>가 존재합니다:</p>

<p>📌 <strong>Redis 서버 부하 증가:</strong></p>

<ul>
  <li>집계 연산의 부하가 애플리케이션에서 Redis 서버로 이동합니다.</li>
  <li>복잡한 스크립트는 Redis의 싱글 스레드 특성으로 인해 다른 작업을 차단할 수 있습니다.</li>
  <li>특히 고부하 상황에서 Redis 서버의 CPU 사용률을 모니터링해야 합니다.</li>
</ul>

<p>📌 <strong>디버깅 복잡성:</strong></p>

<ul>
  <li>Lua 스크립트 내부에서 발생하는 오류는 디버깅이 어렵습니다.</li>
  <li>로그 출력 등 디버깅 정보를 얻기 어려우므로 철저한 테스트가 필요합니다.</li>
  <li>스크립트 오류 시 전체 트랜잭션이 실패할 수 있어 롤백 전략이 필요합니다.</li>
</ul>

<p>📌 <strong>유지보수 복잡성:</strong></p>

<ul>
  <li>Lua 스크립트에 대한 버전 관리와 배포 전략이 필요합니다.</li>
</ul>

<p>📌 <strong>Lua 언어 학습 곡선:</strong></p>

<ul>
  <li>개발팀이 Lua 언어에 익숙하지 않을 경우 추가적인 학습 비용이 발생합니다.</li>
</ul>

<p>📌 <strong>원자성 제한:</strong></p>

<ul>
  <li>Lua 스크립트는 단일 Redis 인스턴스에서는 원자적이지만, 클러스터 환경에서는 원자성이 보장되지 않습니다.</li>
  <li>클러스터에서 여러 키에 걸친 작업을 수행할 때는 모든 키가 동일한 슬롯에 있어야 합니다.</li>
</ul>

<p>📌 <strong>메모리 사용량 증가:</strong></p>

<ul>
  <li>Lua 스크립트 실행 중 생성되는 임시 데이터는 Redis 메모리를 사용합니다.</li>
  <li>대규모 데이터 처리 시 <code class="language-plaintext highlighter-rouge">maxmemory</code> 설정과 메모리 모니터링이 중요합니다.</li>
</ul>

<p>이러한 트레이드 오프를 고려하여, 다음과 같은 상황에서 Lua 스크립트 사용을 권장합니다:</p>

<ul>
  <li>집계, 카운팅 등 단순하고 반복적인 연산이 필요한 경우</li>
  <li>네트워크 왕복을 최소화해야 하는 성능 매우 중요한 상황</li>
  <li>Redis 서버의 리소스가 충분한 경우</li>
</ul>

<p>반면, 다음과 같은 경우는 파이프라인이나 다른 방식을 고려해 볼 수 있습니다:</p>

<ul>
  <li>로직이 매우 복잡하고 자주 변경되는 경우</li>
  <li>Redis 클러스터 환경에서 여러 키를 사용해야 하는 경우</li>
  <li>Redis 서버가 이미 높은 부하를 겪고 있는 경우</li>
</ul>

<h1 id="성능-비교-및-결론">성능 비교 및 결론</h1>
<p>세 가지 구현 방식의 성능을 비교한 결과는 다음과 같습니다:</p>

<ol>
  <li><strong>처리 속도 향상</strong>: <code class="language-plaintext highlighter-rouge">GROUP BY</code> 쿼리 대비 최대 9배 성능 개선</li>
  <li><strong>데이터베이스 부하 감소</strong>: 데이터베이스의 집계 연산 부담 제거</li>
  <li><strong>확장성 향상</strong>: 데이터 증가에도 선형적인 성능 유지</li>
  <li><strong>실시간 집계 가능</strong>: 배치 작업과 실시간 집계를 병행 가능</li>
</ol>

<h1 id="결론">결론</h1>

<p>대용량 데이터 집계가 필요한 <strong>Spring Batch</strong> 애플리케이션에서는 단순히 SQL의 <code class="language-plaintext highlighter-rouge">GROUP BY</code>에 의존하기보다 <strong>Redis</strong>와 같은 인메모리 데이터베이스를 활용하고, <strong>Lua 스크립트</strong>를 통한 서버 사이드 처리를 구현하여 최적의 성능을 얻을 수도 있습니다. 본 포스트가 배치 처리의 성능을 높이는 데 도움이 되었으면 좋겠습니다.</p>

<p>감사합니다.</p>

<hr />

<h1 id="참고-자료">참고 자료</h1>

<ul>
  <li><a href="https://www.youtube.com/watch?v=2IIwQDIi3ys&amp;t=1534s" target="_blank">Batch Performance 극한으로 끌어올리기: 1억 건 데이터 처리를 위한 노력 / if(kakao)dev2022</a></li>
  <li><a href="https://www.youtube.com/watch?v=VSwWHHkdQI4&amp;t=1369s" target="_blank">Spring Batch 애플리케이션 성능 향상을 위한 주요 팁 (kakao tech)</a></li>
  <li><a href="https://redis.io/docs/latest/commands/hincrby/" target="_blank">Redis Commands Docs - hincrby</a></li>
  <li><a href="https://redis.io/docs/latest/commands/hincrbyfloat/" target="_blank">Redis Commands Docs - hincrbyfloat</a></li>
  <li><a href="https://redis.io/docs/latest/develop/interact/programmability/eval-intro/" target="_blank">Redis Docs - Scripting with Lua</a></li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="Spring Batch" /><category term="Spring Batch" /><category term="Redis" /><category term="Aggregation" /><category term="Performance Optimization" /><summary type="html"><![CDATA[데이터 집계를 위한 배치 처리 시 GROUP BY와 SUM 대신 Redis를 활용하여 성능을 대폭 개선할 수 있는 방법에 대해 알아봅시다!]]></summary></entry><entry><title type="html">Spring Batch 대용량 처리의 이해</title><link href="http://localhost:4000/spring%20batch/2025/03/22/Spring-Batch-high-volume-processing/" rel="alternate" type="text/html" title="Spring Batch 대용량 처리의 이해" /><published>2025-03-22T00:00:00+09:00</published><updated>2025-03-22T00:00:00+09:00</updated><id>http://localhost:4000/spring%20batch/2025/03/22/Spring-Batch-high-volume-processing</id><content type="html" xml:base="http://localhost:4000/spring%20batch/2025/03/22/Spring-Batch-high-volume-processing/"><![CDATA[<blockquote>
  <p>스프링 배치를 통한 대용량 처리에 대해 알아봅시다!</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">🚀 들어가기</h1>

<p>본 포스트에서는 배치 처리의 개념과 사용 시나리오를 중심으로, 일괄 생성, 일괄 수정, 통계 처리에 대해 알아보고 대량 데이터 처리 시 발생하는 일반적인 문제점까지 살펴보도록 하겠습니다.</p>

<h1 id="배치-처리의-개념과-사용-시나리오">배치 처리의 개념과 사용 시나리오</h1>

<p><strong>배치(batch) 처리</strong>는 특정 시간에 <strong>많은 데이터를 일괄적으로 처리하는 프로세스</strong>를 의미합니다. 예를 들어, e-커머스 플랫폼에서 오후 4시에 상품 배송 정보를 고객들에게 문자로 일괄 전송하는 경우가 이에 해당합니다. 서버 개발자들은 특정 시간에 일괄 처리해야 하는 작업이 필요할 때 이를 배치 프로세스로 구현하는 것이 일반적입니다.</p>

<h1 id="일괄-생성-일괄-수정-통계-처리-개념">일괄 생성, 일괄 수정, 통계 처리 개념</h1>

<p>배치 처리는 크게 세 가지 형태로 구분할 수 있습니다.</p>

<h2 id="1-일괄-생성read-create-write">1. 일괄 생성(Read-Create-Write)</h2>

<p>기존 저장된 정보를 조합해 새로운 정보를 만듭니다. 예를 들어, 주문 정보를 읽어 사용자 정보와 합친 후 문자 정보를 생성하는 경우가 이에 해당합니다.</p>

<h2 id="2-일괄-수정read-update-write">2. 일괄 수정(Read-Update-Write)</h2>

<p>A 데이터를 읽고 B 데이터를 참고하여 A 데이터를 수정 합니다. 예를 들어, 주문 정보를 읽고 배송 정보를 참고해 주문 정보를 수정합니다.</p>

<h2 id="3-통계-처리read-sum-write">3. 통계 처리(Read-Sum-Write)</h2>

<p>데이터를 집계하여 통계 형식의 데이터를 만듭니다. 예를 들어, 주문 정보를 <code class="language-plaintext highlighter-rouge">GROUP BY</code> 형태로 질의해온 다음 상품별 주문 금액 합산 데이터를 만들 수 있습니다.</p>

<h1 id="사이드-프로젝트-소개">사이드 프로젝트 소개</h1>

<p>스프링 배치의 성능을 최적화하는 <a href="https://github.com/Seung-IL-Bang/spring-batch-optimization-side-project" target="_blank" rel="noopener noreferrer">사이드 프로젝트</a>를 진행했습니다. 이 프로젝트에서는 e-커머스 플랫폼에서 상품을 등록한 판매자에게 일일 정산을 제공하기 위해, 하루 동안 발생한 구매 확정 데이터를 기반으로 매일 특정 시각에 판매자별 일일 정산을 수행하는 배치 프로세스를 구현했습니다.</p>

<p>다음 이미지는 일일 정산 배치를 수행하는 각 단계별 상태를 나타낸 다이어그램입니다.</p>
<figure align="center">
<img src="/post_images/spring-batch-optimization/batch-state-diagram.png" />
<figcaption></figcaption>
</figure>

<ul>
  <li><code class="language-plaintext highlighter-rouge">주문-상품 구매 확정 처리</code>: 특정 조건을 만족시키는 주문-상품 건에 대하여 <strong>구매 확정</strong> 상태로 일괄 수정 합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">클레임 처리 완료</code>: 클레임(취소/환불/반품)이 끝난 건에 대하여 <strong>클레임 완료 처리</strong> 상태로 일괄 수정 합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">판매자별 일일 정산 생성</code>: 금일 판매건이 존재하는 판매자에 대하여 일일 정산을 일괄 생성 합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">주문-상품 정산 Detail 생성</code>: 구매 확정 상태의 주문-상품 건에 대하여 <strong>(+) 정산 처리</strong>한 데이터를 일괄 생성합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">클레임-환불 정산 Detail 생성</code>: 클레임 처리 완료 건 중 환불건에 대하여 <strong>(-) 정산 처리</strong>한 데이터를 일괄 생성합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">판매자별 정산 Detail 집계</code>: 판매자별로 <strong>(+)정산과 (-)정산을 집계</strong>하여 통계 데이터를 생성합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">판매자별 일일 정산 업데이트</code>: 이전 단계에서 생성해두었던 일일 정산에 집계 데이터를 업데이트합니다.</li>
</ul>

<!--일일 정산 배치 프로세스 상태 다이어그램-->

<h1 id="대량-데이터-처리-시-발생하는-일반적인-문제점">대량 데이터 처리 시 발생하는 일반적인 문제점</h1>

<p>개발자들은 종종 배치 성능에 상대적으로 무관심한 경향이 있습니다. 이는 배치 작업이 주로 트래픽이 적은 시간대인 새벽에 자동으로 스케줄링되어 실행되기 때문에, 배치 처리 시간이 오래 걸리더라도 큰 문제로 인식되지 않는 경우가 많기 때문입니다. 또한 배치를 개발한 뒤 배포 후 초기에만 로그를 모니터링하다가, 문제가 없다고 확인된 후에는 실제 문제가 발생하기 전까지 잘 살펴보지 않는 관리 소홀로 이어지기도 합니다. 특히 배치 모니터링 환경이 제대로 구축되어 있지 않다면, 문제를 파악하고 해결하는 데 상당한 시간이 소요될 수 있습니다.</p>

<p>대량 데이터 처리 시 흔히 발생하는 문제점들은 다음과 같습니다:</p>
<ul>
  <li>처리 시간이 예상보다 크게 길어지는 현상</li>
  <li>메모리 부족(OOM, Out Of Memory) 오류 발생</li>
  <li>데이터베이스 부하 증가 및 성능 저하</li>
  <li>동시에 실행되는 배치 작업 간 자원 경쟁으로 인한 성능 저하</li>
  <li>배치 처리 이력 관리 및 모니터링의 어려움</li>
</ul>

<p>사이드 프로젝트를 진행하면서 위 문제들을 어떻게 개선해나갔는지 다음 포스트들에서 하나씩 자세히 살펴보도록 하겠습니다.</p>

<h2 id="감사합니다">감사합니다.</h2>]]></content><author><name>Bang Seung IL</name></author><category term="Spring Batch" /><category term="Spring Batch" /><summary type="html"><![CDATA[스프링 배치를 통한 대용량 처리에 대해 알아봅시다!]]></summary></entry><entry><title type="html">Spring Batch 효과적인 대량 데이터 리드(Read) 전략</title><link href="http://localhost:4000/spring%20batch/2025/03/22/Spring-Batch-Optimized-read-strategy/" rel="alternate" type="text/html" title="Spring Batch 효과적인 대량 데이터 리드(Read) 전략" /><published>2025-03-22T00:00:00+09:00</published><updated>2025-03-22T00:00:00+09:00</updated><id>http://localhost:4000/spring%20batch/2025/03/22/Spring-Batch-Optimized-read-strategy</id><content type="html" xml:base="http://localhost:4000/spring%20batch/2025/03/22/Spring-Batch-Optimized-read-strategy/"><![CDATA[<blockquote>
  <p>스프링 배치를 이용할 때 효과적인 대량 데이터를 읽기 위한 전략에 대해 알아봅시다!</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">🚀 들어가기</h1>

<p>본 포스트에서는 스프링 배치의 핵심 개념인 청크 프로세싱(Chunk Processing)에 대해 알아보고, 대량의 데이터를 효율적으로 읽기 위해 사이드 프로젝트에서 실제 적용한 전략과 그 성능 개선 결과를 공유하고자 합니다.</p>

<h1 id="청크-프로세싱-개념과-중요성">청크 프로세싱 개념과 중요성</h1>

<p>1,000만 개의 데이터를 배치 처리한다고 가정해 보겠습니다. 이러한 대량의 데이터를 한 번에 메모리에 로드하는 것은 물리적으로 불가능하거나 심각한 성능 저하를 초래합니다. 따라서 1,000개씩 나누어 총 10,000번에 걸쳐 처리하는 방식이 필요합니다.</p>

<figure align="center">
<img src="/post_images/spring-batch-optimization/chunk-processing-diagram.svg" />
<figcaption></figcaption>
</figure>

<p>이렇게 메모리 제약을 고려하여 데이터를 일정 크기로 나누어 순차적으로 처리하는 방식을 <strong>청크 프로세싱(Chunk Processing)</strong>이라고 합니다. 스프링 배치는 이러한 청크 단위 처리를 기본 아키텍처로 채택하고 있어 대용량 데이터 처리에 최적화되어 있습니다.</p>

<h1 id="itemreader">ItemReader</h1>

<p>스프링 배치에서 청크 프로세싱을 구현할 때, 데이터 읽기(Read) 역할은 <code class="language-plaintext highlighter-rouge">ItemReader</code> 인터페이스를 구현한 구현체가 담당합니다. 저는 초기에 JPA의 개발 편의성과 페이징 기능을 동시에 활용할 수 있는 <code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>를 사용했습니다. 하지만 실제 대용량 데이터 처리 과정에서 다음과 같은 심각한 한계점을 경험했습니다.</p>

<p><code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>의 주요 문제점:</p>

<ol>
  <li><strong>데이터 일관성 문제</strong>: 조건절에 사용하는 컬럼이 배치 작업 중 업데이트될 경우 페이지네이션 불일치 발생</li>
  <li><strong>JPA 오버헤드</strong>: 불필요한 JPA 기능으로 인한 성능 오버헤드</li>
  <li><strong>Limit-Offset 방식의 구조적 한계</strong>: 오프셋이 증가할수록 기하급수적으로 성능 저하</li>
</ol>

<h1 id="페이지네이션-오류">페이지네이션 오류</h1>

<p><code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>를 사용하면서 가장 먼저 직면한 문제는 페이지네이션이 정확하게 동작하지 않는 현상이었습니다. 예를 들어, 예상했던 10만 건의 처리 대상 데이터 중 약 2만 건만 처리되고 작업이 종료되는 문제가 발생했습니다.</p>

<p>이 문제의 근본 원인은 <code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>의 내부 동작 방식과 <strong>OFFSET 기반 페이징</strong>의 한계에 있었습니다. 스프링 배치는 각 청크 단위로 읽기(<code class="language-plaintext highlighter-rouge">ItemReader</code>) → 처리(<code class="language-plaintext highlighter-rouge">ItemProcessor</code>) → 쓰기(<code class="language-plaintext highlighter-rouge">ItemWriter</code>) 사이클을 반복합니다. <code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>가 동작할 때 발생하는 주요 이슈는 다음과 같습니다:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>는 자체적으로 <code class="language-plaintext highlighter-rouge">EntityManager</code>를 생성하고 관리합니다.</li>
  <li>트랜잭션 내에서 처리될 때, 읽어온 엔티티들은 영속 상태로 유지됩니다.</li>
  <li><code class="language-plaintext highlighter-rouge">Processor</code>나 <code class="language-plaintext highlighter-rouge">Writer</code>에서 엔티티를 업데이트하면, 이 변경사항은 여전히 <code class="language-plaintext highlighter-rouge">Reader</code>의 <code class="language-plaintext highlighter-rouge">EntityManager</code>에 의해 관리됩니다.</li>
  <li>다음 청크를 읽기 위해 ItemReader가 실행될 때, 변경된 내용이 데이터베이스에 반영됩니다.</li>
  <li><strong>LIMIT-OFFSET</strong> 방식의 페이징은 데이터 변경 후에도 원래 개수만큼 <strong>OFFSET</strong>을 증가시키므로 데이터 누락이 발생합니다.</li>
</ol>

<p>초기 작성했던 다음 코드는 이러한 문제 상황을 보여줍니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Override</span>
<span class="nd">@NonNull</span>
<span class="kd">public</span> <span class="nc">Query</span> <span class="nf">createQuery</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="k">this</span><span class="o">.</span><span class="na">getEntityManager</span><span class="o">()</span>
            <span class="o">.</span><span class="na">createQuery</span><span class="o">(</span>
                      <span class="s">"SELECT op "</span> <span class="o">+</span>
                            <span class="s">"FROM OrderProduct op "</span> <span class="o">+</span>
                            <span class="s">"LEFT JOIN Claim cl ON op.orderProductId = cl.orderProductId "</span> <span class="o">+</span>
                            <span class="s">"WHERE op.deliveryCompletedAt BETWEEN :startTime AND :endTime "</span> <span class="o">+</span>
                            <span class="s">"AND op.deliveryStatus = 'DELIVERED' "</span> <span class="o">+</span>
                            <span class="s">"AND op.purchaseConfirmedAt IS NULL "</span> <span class="o">+</span>
                            <span class="s">"AND (cl.claimId IS NULL OR cl.completedAt IS NOT NULL) "</span> <span class="o">+</span>
                            <span class="s">"ORDER BY op.orderProductId ASC"</span><span class="o">,</span> <span class="nc">OrderProduct</span><span class="o">.</span><span class="na">class</span><span class="o">)</span>
            <span class="o">.</span><span class="na">setParameter</span><span class="o">(</span><span class="s">"startTime"</span><span class="o">,</span> <span class="n">startTime</span><span class="o">)</span>
            <span class="o">.</span><span class="na">setParameter</span><span class="o">(</span><span class="s">"endTime"</span><span class="o">,</span> <span class="n">endTime</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>위 쿼리와 함께 발생하는 구체적인 문제 시나리오:</p>

<ol>
  <li>조건절에 <code class="language-plaintext highlighter-rouge">purchaseConfirmedAt IS NULL</code> 조건이 포함되어 있습니다.</li>
  <li>청크 크기를 1,000으로 설정하여 첫 번째 1,000개 레코드(ID 1~1000)를 읽고 처리합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">ItemWriter</code> 단계에서 처리된 레코드의 <code class="language-plaintext highlighter-rouge">purchaseConfirmedAt</code> 필드가 현재 시간으로 업데이트됩니다.</li>
  <li>두 번째 청크 작업 시, <code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>는 다음과 같은 내부 쿼리를 생성합니다:</li>
</ol>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">op</span> <span class="k">FROM</span> <span class="n">OrderProduct</span> <span class="n">op</span>
<span class="k">WHERE</span> <span class="n">op</span><span class="p">.</span><span class="n">deliveryCompletedAt</span> <span class="k">BETWEEN</span> <span class="p">:</span><span class="n">startTime</span> <span class="k">AND</span> <span class="p">:</span><span class="n">endTime</span>
<span class="k">AND</span> <span class="n">op</span><span class="p">.</span><span class="n">deliveryStatus</span> <span class="o">=</span> <span class="s1">'DELIVERED'</span>
<span class="k">AND</span> <span class="n">op</span><span class="p">.</span><span class="n">purchaseConfirmedAt</span> <span class="k">IS</span> <span class="k">NULL</span>
<span class="k">AND</span> <span class="p">(</span><span class="n">cl</span><span class="p">.</span><span class="n">claimId</span> <span class="k">IS</span> <span class="k">NULL</span> <span class="k">OR</span> <span class="n">cl</span><span class="p">.</span><span class="n">completedAt</span> <span class="k">IS</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">)</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="n">op</span><span class="p">.</span><span class="n">orderProductId</span> <span class="k">ASC</span>
<span class="k">OFFSET</span> <span class="mi">1000</span> <span class="k">LIMIT</span> <span class="mi">1000</span>
</code></pre></div></div>

<ul>
  <li>그러나 이 시점에서 처음 1,000개 레코드는 이미 <code class="language-plaintext highlighter-rouge">purchaseConfirmedAt IS NULL</code> 조건을 더 이상 만족하지 않게 됩니다.</li>
  <li>따라서 원래 데이터베이스에서 1001~2000 ID를 가진 레코드들이 아닌, 새롭게 조건을 만족하는 처음 1,000개 중에서 OFFSET 1000을 적용하게 됩니다.</li>
  <li>이로 인해 원래 처리되어야 할 데이터 중 일부(OFFSET으로 인해 건너뛰는 데이터)가 누락되는 현상이 발생합니다.</li>
</ul>

<p>이러한 문제의 근본적인 원인은 <code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>가 내부적으로 채택하고 있는 <strong>LIMIT-OFFSET</strong> 방식의 페이징과 <code class="language-plaintext highlighter-rouge">EntityManager</code>의 영속성 관리 방식이 조합되어 발생하는 구조적 한계에 있습니다.</p>

<p>따라서 <code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>은 <strong>처리 과정에서 조건절의 컬럼이 변경될 경우, 페이지네이션 로직이 정상적으로 동작하지 않아 데이터 누락이 발생</strong>합니다.</p>

<h1 id="limit-offset-방식의-한계">Limit-Offset 방식의 한계</h1>

<p><code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>가 사용하는 <code class="language-plaintext highlighter-rouge">Limit-Offset</code> 페이지네이션 방식은 대용량 데이터 처리 시 치명적인 성능 저하를 초래합니다. 이 방식의 핵심적인 문제는 <strong>오프셋이 커질수록 데이터베이스가 처리해야 하는 작업량이 기하급수적으로 증가</strong>한다는 점입니다.</p>

<p>예를 들어, <code class="language-plaintext highlighter-rouge">LIMIT 1000 OFFSET 9000</code>과 같은 쿼리를 실행할 경우:</p>

<ol>
  <li>데이터베이스는 처음부터 9,000번째 레코드까지 모두 스캔합니다.</li>
  <li>그 후 9,001번째부터 10,000번째까지의 1,000개 레코드만 실제로 반환합니다.</li>
</ol>

<p>즉, 오프셋이 커질수록 실제로 <strong>필요한 데이터는 일정한데 반해, 스캔해야 하는 데이터는 계속 증가</strong>하게 됩니다. 수천만 건의 데이터를 처리해야 하는 배치 작업에서 이러한 방식은 심각한 성능 병목을 야기합니다.</p>

<h1 id="limit-offset-vs-zero-offset-비교-다이어그램">Limit-Offset vs Zero-Offset 비교 다이어그램</h1>

<figure align="center">
<img src="/post_images/spring-batch-optimization/offset-comparison-diagram.svg" />
<figcaption></figcaption>
</figure>

<p>위 다이어그램은 두 방식의 차이점을 명확하게 보여주는 자료입니다. Limit-Offset의 구조적 한계점 때문에 왜 <strong>Zero-Offset</strong> 방식이 필요한지를 이해할 수 있습니다.</p>

<h1 id="zero-offset-아이템-리더-구현과-성능-개선">Zero-Offset 아이템 리더 구현과 성능 개선</h1>

<p><code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code>의 한계를 극복하기 위해, 저는 <code class="language-plaintext highlighter-rouge">Zero-Offset</code> 방식(또는 <strong>키셋 페이징</strong>)을 구현한 커스텀 ItemReader를 개발했습니다.</p>

<p><strong>Zero-Offset</strong> 방식의 핵심 아이디어는 다음과 같습니다:</p>

<ol>
  <li><strong>항상 오프셋을 0으로 유지</strong>: 페이지 이동 시에도 항상 OFFSET 0을 사용</li>
  <li><strong>ID 기반 필터링</strong>: 이전 페이지에서 처리한 마지막 레코드의 ID를 기준으로 다음 데이터를 조회</li>
  <li><strong>PK 인덱스 활용</strong>: 기본키(PK) 인덱스를 최대한 활용하여 조회 성능 최적화</li>
</ol>

<p>구현을 위한 필수 조건:</p>

<ol>
  <li>PK를 기준으로 데이터를 명시적으로 정렬 (예: <code class="language-plaintext highlighter-rouge">ORDER BY id ASC</code>)</li>
  <li>각 페이지 조회 시, 이전 페이지의 마지막 ID 값을 기준으로 필터링 조건 추가 (예: <code class="language-plaintext highlighter-rouge">WHERE id &gt; :lastId</code>)</li>
</ol>

<p>예를 들어, 첫 번째 페이지에서 1,000건을 조회한 후 마지막 레코드의 ID가 1000이라면, 두 번째 페이지 조회 시에는 다음과 같은 쿼리에 <code class="language-plaintext highlighter-rouge">:lastId</code>에 1000을 설정해주면 됩니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">order_product</span> 
<span class="k">WHERE</span> <span class="p">...</span> <span class="k">AND</span> <span class="n">order_product_id</span> <span class="o">&gt;</span> <span class="p">:</span><span class="n">lastId</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="n">order_product_id</span> <span class="k">ASC</span> 
<span class="k">LIMIT</span> <span class="mi">1000</span>
</code></pre></div></div>

<p>이 방식의 장점은 페이지 번호가 아무리 뒤로 가더라도 항상 인덱스를 타는 효율적인 쿼리가 실행된다는 점입니다. 결과적으로 일관된 성능을 유지할 수 있으며, 데이터 일관성 문제도 해결할 수 있습니다.</p>

<h1 id="커서-기반-아이템-리더-활용과-성능-개선">커서 기반 아이템 리더 활용과 성능 개선</h1>

<p><strong>Zero-Offset</strong> 방식 외에도, <strong>커서 기반(Cursor-based)</strong> 아이템 리더를 활용하는 방법도 효과적입니다. 스프링 배치는 <strong>JdbcCursorItemReader</strong>와 같은 커서 기반 구현체를 제공합니다.</p>

<p>커서 기반 방식의 주요 특징:</p>

<ol>
  <li><strong>스트리밍 방식</strong>: 데이터베이스 커서를 통해 필요한 만큼만 데이터를 스트리밍 방식으로 가져옴</li>
  <li><strong>메모리 효율성</strong>: 전체 결과셋을 메모리에 로드하지 않고 필요한 만큼만 가져오므로 메모리 효율적</li>
  <li><strong>성능 일관성</strong>: Limit-Offset 방식의 성능 저하 없이 대량 데이터 처리 가능</li>
</ol>

<p>🚨 다만, 커서 기반 접근법은 다음과 같은 고려사항이 있습니다:</p>

<ol>
  <li><strong>데이터베이스 연결 유지</strong>: 처리가 완료될 때까지 데이터베이스 연결을 유지해야 함. (충분한 <code class="language-plaintext highlighter-rouge">Connection-time</code> 설정 필요.)</li>
  <li><strong>트랜잭션 범위</strong>: 장시간 실행되는 작업의 경우 트랜잭션 관리에 주의 필요.</li>
  <li><strong>리소스 관리</strong>: 커서를 명시적으로 닫아야 하므로 리소스 관리에 신경 써야 함. (<code class="language-plaintext highlighter-rouge">JdbcCursorItemReader</code>는 리소스를 자동으로 정리.)</li>
</ol>

<h1 id="최종-선택-커서-기반-접근법-jdbccursoritemreader">최종 선택: 커서 기반 접근법 JdbcCursorItemReader</h1>

<p>이론적으로는 <strong>Zero-Offset</strong> 방식이 매우 효율적이지만, 실제 프로젝트에서는 <strong>커서 기반 접근법(Cursor-based approach)</strong>을 최종적으로 채택했습니다. 이러한 결정을 내린 주요 이유는 다음과 같습니다:</p>

<ul>
  <li><strong>개발 리소스 효율성</strong>: Zero-Offset 방식은 매번 새로운 Reader를 구현할 때마다 상당한 개발 공수가 필요합니다. 반면 Spring Batch에서 기본 제공하는 <code class="language-plaintext highlighter-rouge">JdbcCursorItemReader</code>를 사용하면 즉시 활용 가능합니다.</li>
  <li><strong>유지보수 용이성</strong>: 커스텀 구현체보다 Spring Batch의 공식 컴포넌트를 사용함으로써 유지보수가 용이하고 버전 업그레이드 시 호환성 문제가 적습니다.</li>
  <li><strong>성능 대비 비용</strong>: Zero-Offset 방식이 이론적으로 약간 더 뛰어난 성능을 보일 수 있지만, 커서 기반 접근법도 충분히 우수한 성능을 제공하면서 개발 비용은 크게 절감할 수 있었습니다.</li>
</ul>

<p>⭐️ 따라서, 성능상 크게 차이가 안 나는 <strong>Zero-Offset</strong> 방식과 <strong>Cursor-Based</strong> 방식 중 실용적인 측면을 생각하여 Cursor-based인 <code class="language-plaintext highlighter-rouge">JdbcCursorItemReader</code> 를 프로젝트에 적용하였습니다.</p>

<p>다음은 실제 구현에 사용한 <code class="language-plaintext highlighter-rouge">JdbcCursorItemReader</code> 설정의 코드입니다:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Bean</span>
<span class="nd">@StepScope</span>
<span class="kd">public</span> <span class="nc">JdbcCursorItemReader</span><span class="o">&lt;</span><span class="nc">OrderProduct</span><span class="o">&gt;</span> <span class="nf">deliveryCompletedJdbcItemReader</span><span class="o">(</span>
        <span class="nd">@Value</span><span class="o">(</span><span class="s">"#{jobParameters['settlementDate']}"</span><span class="o">)</span> <span class="nc">String</span> <span class="n">settlementDateStr</span><span class="o">)</span> <span class="o">{</span>

    <span class="nc">LocalDate</span> <span class="n">date</span> <span class="o">=</span> <span class="nc">JobParameterUtils</span><span class="o">.</span><span class="na">parseSettlementDate</span><span class="o">(</span><span class="n">settlementDateStr</span><span class="o">);</span>
    <span class="nc">LocalDateTime</span> <span class="n">startTime</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="na">atStartOfDay</span><span class="o">();</span>
    <span class="nc">LocalDateTime</span> <span class="n">endTime</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="na">plusDays</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="na">atStartOfDay</span><span class="o">();</span>

    <span class="c1">// SQL 쿼리 작성</span>
    <span class="nc">String</span> <span class="n">sql</span> <span class="o">=</span> <span class="s">"""
        SELECT op.*
        FROM order_product op
        LEFT JOIN claim cl ON op.order_product_id = cl.order_product_id
        WHERE op.delivery_completed_at BETWEEN ? AND ?
        AND op.delivery_status = 'DELIVERED'
        AND op.purchase_confirmed_at IS NULL
        AND (cl.claim_id IS NULL OR cl.completed_at IS NOT NULL)
        ORDER BY op.order_product_id ASC
        """</span><span class="o">;</span>

    <span class="c1">// PreparedStatement 파라미터 설정</span>
    <span class="nc">Object</span><span class="o">[]</span> <span class="n">parameters</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Object</span><span class="o">[]</span> <span class="o">{</span>
            <span class="n">startTime</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="nc">DateTimeFormatter</span><span class="o">.</span><span class="na">ofPattern</span><span class="o">(</span><span class="s">"yyyy-MM-dd HH:mm:ss"</span><span class="o">)),</span>
            <span class="n">endTime</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="nc">DateTimeFormatter</span><span class="o">.</span><span class="na">ofPattern</span><span class="o">(</span><span class="s">"yyyy-MM-dd HH:mm:ss"</span><span class="o">))</span>
    <span class="o">};</span>

    <span class="k">return</span> <span class="k">new</span> <span class="nc">JdbcCursorItemReaderBuilder</span><span class="o">&lt;</span><span class="nc">OrderProduct</span><span class="o">&gt;()</span>
            <span class="o">.</span><span class="na">name</span><span class="o">(</span><span class="s">"deliveryCompletedJdbcItemReader"</span><span class="o">)</span>
            <span class="o">.</span><span class="na">dataSource</span><span class="o">(</span><span class="n">dataSource</span><span class="o">)</span>
            <span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="n">sql</span><span class="o">)</span>
            <span class="o">.</span><span class="na">preparedStatementSetter</span><span class="o">(</span><span class="k">new</span> <span class="nc">ArgumentPreparedStatementSetter</span><span class="o">(</span><span class="n">parameters</span><span class="o">))</span>
            <span class="o">.</span><span class="na">rowMapper</span><span class="o">(</span><span class="k">new</span> <span class="nc">BeanPropertyRowMapper</span><span class="o">&lt;&gt;(</span><span class="nc">OrderProduct</span><span class="o">.</span><span class="na">class</span><span class="o">))</span>
            <span class="o">.</span><span class="na">build</span><span class="o">();</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li><strong>Zero-Offset</strong> 방식의 <code class="language-plaintext highlighter-rouge">ItemReader</code>를 직접 개발하는 것보다 Spring Batch에서 지원해주는 <code class="language-plaintext highlighter-rouge">JdbcCursorItemReader</code>를 사용함으로써 매번 <code class="language-plaintext highlighter-rouge">:lastId</code>를 신경쓰지 않고도 편리하게 개발할 수 있습니다.</li>
</ul>

<h1 id="성능-비교-jpa-paging-vs-cursor-based">성능 비교: JPA Paging vs Cursor-based</h1>

<p>실제 동일한 데이터셋(최대 100만 건의 주문 데이터)에 대해 두 가지 방식을 적용한 성능 비교 결과는 다음과 같습니다:</p>

<figure align="center">
<img src="/post_images/spring-batch-optimization/realistic-performance-comparison.svg" />
<figcaption></figcaption>
</figure>

<p>참고로, <code class="language-plaintext highlighter-rouge">JpaPagingItemReader</code> 읽기가 2만건 처리에 6분이 걸렸고, 그 이상의 데이터는 테스트하기 어려웠던 현실적인 상황을 반영하여 추정치를 표시했습니다.</p>

<p>성능 테스트 결과 분석:</p>

<ul>
  <li><strong>JPA Paging</strong>: 데이터량이 증가할수록 처리 시간이 <strong>기하급수적으로 증가</strong>함.</li>
  <li><strong>Cursor-based</strong>: 빠른 처리 속도를 보이며, 데이터량이 증가하더라도 처리 시간이 <strong>선형적으로 증가</strong>함.</li>
</ul>

<h1 id="보완할-점">보완할 점</h1>

<p>현재 구현에서 가장 큰 개선점은 타입 안전성입니다. 문자열 기반 쿼리를 사용하는 현재 방식은 오타나 컬럼명 변경 시 컴파일 타임에 오류를 잡아내기 어렵습니다.</p>

<p>향후 개선 방향:</p>

<ul>
  <li><strong>QueryDSL 도입</strong>: Java 코드로 타입 안전한 쿼리를 작성하여 컴파일 타임에 오류 감지</li>
  <li><strong>테스트 커버리지 강화</strong>: 다양한 데이터 패턴에 대한 테스트 케이스 추가</li>
  <li><strong>모니터링 기능 개선</strong>: 배치 작업의 진행 상황 및 성능 지표 실시간 모니터링</li>
</ul>

<p>Kotlin 기반 프로젝트의 경우, <strong>Exposed 라이브러리</strong>를 활용하면 더욱 간결하고 타입 안전한 방식으로 쿼리를 작성하실 수 있으니 참고하시면 좋을 것 같습니다.</p>

<h1 id="️-결론">⭐️ 결론</h1>

<p>대용량 데이터 처리 시 Spring Batch의 <code class="language-plaintext highlighter-rouge">ItemReader</code> 전략은 전체 배치 프로세스의 성능과 안정성에 결정적인 영향을 미칩니다. 특히 <code class="language-plaintext highlighter-rouge">Limit-Offset</code> 방식의 페이징 대신 <strong>Zero-Offset</strong> 또는 <strong>커서 기반 접근법</strong>을 활용함으로써 다음과 같은 이점을 얻을 수 있습니다:</p>

<ul>
  <li><strong>일관된 성능</strong>: 처리 데이터량에 관계없이 예측 가능한 성능 유지</li>
  <li><strong>데이터 일관성</strong>: 배치 처리 중 데이터 변경에도 페이지네이션 정확성 보장</li>
  <li><strong>리소스 효율성</strong>: 데이터베이스와 애플리케이션 서버의 리소스 효율적 활용</li>
</ul>

<p>대규모 배치 작업을 설계할 때는 단순히 <strong>코드 작성의 편의성보다 성능과 확장성을 우선적으로 고려하는 것이 중요</strong>합니다. 본 포스트에서 소개한 전략들이 효율적인 배치 시스템 구축에 도움이 되길 바랍니다.</p>

<h1 id="참고-자료">참고 자료</h1>

<ul>
  <li><a href="https://www.youtube.com/watch?v=2IIwQDIi3ys&amp;t=1534s" target="_blank">Batch Performance 극한으로 끌어올리기: 1억 건 데이터 처리를 위한 노력 / if(kakao)dev2022</a></li>
  <li><a href="https://www.youtube.com/watch?v=VSwWHHkdQI4&amp;t=1369s" target="_blank">Spring Batch 애플리케이션 성능 향상을 위한 주요 팁 (kakao tech)</a></li>
  <li><a href="https://docs.spring.io/spring-batch/reference/5.2-SNAPSHOT/readers-and-writers/database.html#JdbcCursorItemReader" target="_blank">Spring Batch Documentation: Cursor-based ItemReader Implementations</a></li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="Spring Batch" /><category term="Spring Batch" /><category term="Zero Offset" /><category term="Limit-Offset" /><category term="Cursor-Based" /><summary type="html"><![CDATA[스프링 배치를 이용할 때 효과적인 대량 데이터를 읽기 위한 전략에 대해 알아봅시다!]]></summary></entry><entry><title type="html">Spring Boot + Prometheus + Grafana로 마이크로서비스 모니터링 시스템 구축</title><link href="http://localhost:4000/msa/monitoring/prometheus/grafana/2025/02/24/Prometheus-Grafana-Monitoring/" rel="alternate" type="text/html" title="Spring Boot + Prometheus + Grafana로 마이크로서비스 모니터링 시스템 구축" /><published>2025-02-24T00:00:00+09:00</published><updated>2025-02-24T00:00:00+09:00</updated><id>http://localhost:4000/msa/monitoring/prometheus/grafana/2025/02/24/Prometheus-Grafana-Monitoring</id><content type="html" xml:base="http://localhost:4000/msa/monitoring/prometheus/grafana/2025/02/24/Prometheus-Grafana-Monitoring/"><![CDATA[<blockquote>
  <p>Prometheus와 Grafana를 활용하여 Spring Boot 기반 마이크로서비스를 모니터링 하는 방법에 대해 알아봅시다!</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">📌 들어가기</h1>

<p>현대의 마이크로서비스 아키텍처는 여러 개의 독립적인 서비스가 유기적으로 협력하여 하나의 큰 시스템을 구성합니다. 마이크로서비스 환경에서는 각 서비스가 독립적으로 배포되고 운영되기 때문에, 특정 서비스의 장애나 성능 저하가 전체 시스템에 영향을 줄 수 있습니다. 만약 모니터링 시스템이 없다면 서비스 장애나 성능 저하 발생 시 원이 파악에 오랜 시간이 소요되어 비즈니스에 심각한 영향을 미칠 수 있습니다. 이런 서비스 장애가 지속되면 사용자 경험이 악화되고, 결과적으로 서비스의 신뢰를 잃어버리는 최악의 상황이 올 수 있습니다. 따라서 MSA 환경에서는 각 서비스의 상태와 성능을 실시간으로 모니터링하는 것이 필수적입니다.</p>

<p>본 포스트에서는 <code class="language-plaintext highlighter-rouge">Prometheus</code>와 <code class="language-plaintext highlighter-rouge">Grafana</code>를 활용하여 Spring Boot 기반 마이크로서비스를 모니터링하는 방법에 대해 알아보도록 하겠습니다.</p>

<h1 id="promethus--grafana">Promethus &amp; Grafana</h1>

<p>우선 Prometheus와 Grafana가 각각 무엇인지 알아봅시다.</p>

<h2 id="prometheus란">Prometheus란?</h2>

<p><code class="language-plaintext highlighter-rouge">Prometheus</code>는 오픈소스 모니터링 및 경고 도구로, 주로 <strong>시계열 데이터</strong>를 수집하여 저장, 쿼리, 분석하는 데 사용되는 저장소입니다. 특히 시계열 데이터에 특화된 쿼리 언어인 <strong>PromQL</strong>을 제공하여, 수집한 메트릭을 조회할 수 있습니다.</p>

<h2 id="grafana란">Grafana란?</h2>

<p><code class="language-plaintext highlighter-rouge">Grafana</code>는 <code class="language-plaintext highlighter-rouge">Prometheus</code>에서 수집한 데이터를 직관적인 대시보드 형태로 시각화하는 시각화 도구입니다. Prometheus 뿐만 아니라 다양한 데이터 소스와의 연동도 지원합니다. 대시보드를 커스텀할 수 있을 뿐만 아니라 경고 시스템도 구축 가능합니다.</p>

<h1 id="spring-boot와-prometheus-연동">Spring Boot와 Prometheus 연동</h1>

<p>Spring Boot는 <strong>Actuator</strong> 모듈을 통해 애플리케이션의 다양한 상태 정보(<strong>metrics</strong>)를 쉽게 노출할 수 있습니다. 이를 활용하여 Prometheus가 <strong>Pull 방식</strong>으로 메트릭 데이터를 수집할 수 있도록 설정할 수 있습니다.</p>

<p>Actuator 모듈을 통해 스프링 애플리케이션의 메트릭 정보들을 Prometheus에게 노출하기 위해 다음 의존성을 추가해줘야 합니다.</p>

<div class="language-groovy highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">implementation</span> <span class="s1">'org.springframework.boot:spring-boot-starter-actuator'</span>
<span class="n">implementation</span> <span class="s1">'io.micrometer:micrometer-registry-prometheus'</span>
</code></pre></div></div>

<p>그리고, Prometheus가 Pull 방식으로 메트릭을 조회할 Actuator 엔드포인트를 활성화시켜 줘야 합니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">management</span><span class="pi">:</span>
  <span class="na">endpoints</span><span class="pi">:</span>
    <span class="na">web</span><span class="pi">:</span>
      <span class="na">exposure</span><span class="pi">:</span>
        <span class="na">include</span><span class="pi">:</span> <span class="s">prometheus</span>
</code></pre></div></div>

<p>마지막으로 Promethues.yml 설정 파일을 통해 Prometheus가 Pull 하고자 하는 애플리케이션의 위치 정보를 설정해주어야 합니다.</p>

<p>아래 설정은 동일한 도커 네트워크 상에 존재하는 <code class="language-plaintext highlighter-rouge">user service</code>, <code class="language-plaintext highlighter-rouge">product service</code>, <code class="language-plaintext highlighter-rouge">order service</code>에 대한 메트릭을 Pull을 5초 간격으로 진행하겠단 설정입니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">global</span><span class="pi">:</span>
  <span class="na">scrape_interval</span><span class="pi">:</span> <span class="s">15s</span>
  <span class="na">external_labels</span><span class="pi">:</span>
    <span class="na">monitor</span><span class="pi">:</span> <span class="s1">'</span><span class="s">codelab-monitor'</span>
<span class="na">scrape_configs</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">job_name</span><span class="pi">:</span> <span class="s1">'</span><span class="s">prometheus'</span>
    <span class="na">scrape_interval</span><span class="pi">:</span> <span class="s">5s</span>
    <span class="na">static_configs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">targets</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">localhost:9090'</span><span class="pi">]</span>
  <span class="pi">-</span> <span class="na">job_name</span><span class="pi">:</span> <span class="s1">'</span><span class="s">user-actuator'</span>
    <span class="na">metrics_path</span><span class="pi">:</span> <span class="s1">'</span><span class="s">/actuator/prometheus'</span>
    <span class="na">scrape_interval</span><span class="pi">:</span> <span class="s">5s</span>
    <span class="na">static_configs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">targets</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">user-service:8080'</span><span class="pi">]</span>
      <span class="pi">-</span> <span class="na">targets</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">product-service:8081'</span><span class="pi">]</span>
      <span class="pi">-</span> <span class="na">targets</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">order-service:8082'</span><span class="pi">]</span>
</code></pre></div></div>

<p>만약 로컬에 설치된 Prometheus가 아닌 도커로 실행 시, Prometheus의 <code class="language-plaintext highlighter-rouge">/etc/prometheus/prometheus.yml</code> 경로와 커스텀 설정 파일을 볼륨 마운팅 해주어야 합니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3.8'</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">prometheus</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">prom/prometheus:latest</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">prometheus</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">./prometheus.yml:/etc/prometheus/prometheus.yml</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">9090:9090"</span>
</code></pre></div></div>

<p>위 설정이 완료되면 Prometheus는 <code class="language-plaintext highlighter-rouge">http://&lt;호스트&gt;:&lt;포트&gt;/actuator/prometheus</code> 엔드포인트를 통해 Spring Boot 애플리케이션들의 메트릭 데이터를 수집할 수 있습니다.</p>

<h1 id="prometheus-메트릭---grafana-시각화">Prometheus 메트릭 -&gt; Grafana 시각화</h1>

<p>메트릭 데이터들이 Prometheus에 저장되면 이와 연동하여 Grafana를 통해 시각화할 수 있습니다.</p>

<p>Grafana 관리 페이지에서 데이터 소스로 Prometheus를 추가한 다음, URL에 Prometheus 서버의 주소(<code class="language-plaintext highlighter-rouge">http://&lt;prometheus-host&gt;:9090</code>)를 입력합니다.</p>

<p>대시보드를 개인이 직접 커스터마이징할 수도 있지만, 이미 잘 만들어진 대시보드 템플릿을 가져다 사용하면 편리합니다.</p>

<h1 id="-결론">🚀 결론</h1>

<p><strong>Prometheus</strong>와 <strong>Grafana</strong>를 활용한 모니터링 시스템은 마이크로서비스 환경에서 서비스의 상태를 실시간으로 확인하고, 장애 발생 시 빠른 대응을 가능하게 합니다. 모니터링 시스템은 필수적이며, 이를 부재할 경우 심각한 비즈니스 리스크를 초래할 수 있다는 것을 명심해야 됩니다.</p>

<h1 id="추가로-공부하면-좋을-내용">추가로 공부하면 좋을 내용</h1>

<ul>
  <li>Grafana Alerting 기능 (특정 메트릭 값이 임계치 초과 시 알림 발송)</li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="MSA" /><category term="Monitoring" /><category term="Prometheus" /><category term="Grafana" /><category term="Prometheus" /><category term="Grafana" /><summary type="html"><![CDATA[Prometheus와 Grafana를 활용하여 Spring Boot 기반 마이크로서비스를 모니터링 하는 방법에 대해 알아봅시다!]]></summary></entry><entry><title type="html">ELK 스택을 활용한 MSA 중앙 집중식 로그 모니터링</title><link href="http://localhost:4000/msa/elk/2025/02/24/ELK-Stack-Log-Analysis/" rel="alternate" type="text/html" title="ELK 스택을 활용한 MSA 중앙 집중식 로그 모니터링" /><published>2025-02-24T00:00:00+09:00</published><updated>2025-02-24T00:00:00+09:00</updated><id>http://localhost:4000/msa/elk/2025/02/24/ELK-Stack-Log-Analysis</id><content type="html" xml:base="http://localhost:4000/msa/elk/2025/02/24/ELK-Stack-Log-Analysis/"><![CDATA[<blockquote>
  <p>마이크로서비스 아키텍처에서 ELK(Elasticsearch + Logstash + Kibana) 스택을 활용한 중앙 집중식 로그 모니터링에 대해 알아봅시다!</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">📌 들어가기</h1>

<p>최근 마이크로서비스 아키텍처가 널리 사용되면서, 다양한 서비스에서 발생하는 로그를 효과적으로 수집 및 분석할 수 있는 방법이 필요해졌습니다. 마이크로서비스 환경에서는 각 서비스마다 별도의 로그 파일이 생성됩니다. 개별 서버마다 분산되어 저장된 로그 파일을 일일이 분석하는 것은 매우 고된 일이 될 것입니다. 그리고 문제 발생 시 신속하게 로그를 추적하여 원인을 파악하고 대응하는 데에 많은 시간이 소모될 것입니다. 이처럼 MSA 환경에서 로그를 중앙 집중식으로 관리하지 않는다면 여러 가지 문제가 발생할 수 밖에 없습니다.</p>

<p>이에 따라 ELK(Elasticsearch + Logstash + Kibana)를 활용한 중앙 집중식 로그 모니터링의 필요성이 더욱 부각되고 있습니다.</p>

<p>본 포스트에서는 ELK 스택 기반의 로그 모니터링 구성과, Zipkin 로그 트레이싱과의 연계를 통한 효율적인 모니터링 방법에 대해 살펴보도록 하겠습니다. <a href="https://seung-il-bang.github.io/spring%20cloud/zipkin/msa/2025/02/23/Zipkin-Distributed-Tracing/#">Zipkin 로그 트레이싱</a>과 관련한 포스트가 있으니 참고하시면 좋을 것 같습니다.</p>

<h1 id="elk-도입의-효과">ELK 도입의 효과</h1>

<h2 id="logstash를-통한-로그-수집-및-필터링">Logstash를 통한 로그 수집 및 필터링</h2>

<p>Logstash는 다양한 소스의 로그를 실시간으로 수집하고, 필터링 및 가공하여 일관된 포맷으료 변환해줍니다. 이를 통해 수집된 로그의 품질을 높이고, 분석의 효율성을 높일 수 있습니다. 개인 사이드 프로젝트에서는 각 서비스가 로그 파일을 각 서버가 저장하도록 했고, 해당 로그 파일을 Logstash가 수집하도록 설정했습니다.</p>

<h2 id="elasticsearch-기반의-빠른-검색">Elasticsearch 기반의 빠른 검색</h2>

<p>Elasticsearch는 분산형 검색 엔진으로, 대용량 로그 데이터를 빠르게 인덱싱 및 검색할 수 있습니다. 덕분에 서비스 장애 시 빠른 속도의 로그 검색으로 인하여 문제를 신속하게 대응할 수 있게 됩니다.</p>

<h2 id="kibana-대시보드를-통한-시각화">Kibana 대시보드를 통한 시각화</h2>

<p>Kibana는 Elasticsearch에 저장된 로그 데이터를 시각화하여 대시보드를 구성할 수 있게 해줍니다. 이를 통해 로그의 흐름과 이상 징후를 한눈에 파악할 수 있으며, 실시간 모니터링 환경을 구축할 수 있습니다.</p>

<h1 id="logback과-elk-연동-및-구성-방법">Logback과 ELK 연동 및 구성 방법</h1>

<h2 id="logback이란">Logback이란?</h2>
<p>스프링 부트는 <strong>로깅 시스템의 기본 구현체</strong>로 <code class="language-plaintext highlighter-rouge">Logback</code>을 사용하도록 설정되어 있습니다. 기본적인 성능과 기능이 좋기 때문에 많이 사용되고 있습니다. 만약 설정을 커스텀하고 싶다면 <code class="language-plaintext highlighter-rouge">logback.xml</code> 파일로 설정을 조정하실 수도 있습니다.</p>

<p>스프링 부트 프로젝트에서 개발 편의성을 위해 <code class="language-plaintext highlighter-rouge">Lombok</code>을 대부분 사용하실 겁니다. 해당 라이브러리에는 <code class="language-plaintext highlighter-rouge">Slf4j(Simple Logging Facade For Java)</code>라는 로그 시스템에 대한 추상화 계층을 제공하는 인터페이스가 존재합니다. Slf4j의 기본 구현체는 <code class="language-plaintext highlighter-rouge">Logback</code>으로 설정되어 있습니다. <strong>Slf4j 자체는 인터페이스</strong>이므로 로깅을 수행하지 않고, <strong>실제 로깅을 수행하는 구현체(ex: Logback, Log4j 등)에게 위임</strong>합니다. 만약 로깅 구현체를 교체하고 싶다면, 의존성을 변경함으로써 쉽게 교체할 수 있습니다.</p>

<h2 id="logback---logstash-로그-전송">Logback -&gt; Logstash 로그 전송</h2>

<p>logback 로깅 시스템을 통해 Logstash로 로그를 전송하기 위해선 다음 의존성부터 추가해줘야 합니다. 그런 다음 <code class="language-plaintext highlighter-rouge">logback.xml</code> 설정에 Logstash로 로그를 출력하는 <strong>Appender</strong>를 추가해주면 됩니다.</p>

<div class="language-groovy highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">implementation</span> <span class="s1">'net.logstash.logback:logstash-logback-encoder:8.0'</span>
</code></pre></div></div>

<p>아래 XML 설정은 스프링 애플리케이션에 설정된 <code class="language-plaintext highlighter-rouge">logback.xml</code> 설정입니다. 해당 설정은 실시간으로 발생되는 <strong>로그를 콘솔, 파일, Logstash에 각각 출력</strong>하는 설정입니다.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;springProperty</span> <span class="na">scope=</span><span class="s">"context"</span> <span class="na">name=</span><span class="s">"applicationName"</span> <span class="na">source=</span><span class="s">"spring.application.name"</span> <span class="na">defaultValue=</span><span class="s">"defaultAppName"</span> <span class="nt">/&gt;</span>
    <span class="nt">&lt;springProperty</span> <span class="na">scope=</span><span class="s">"context"</span> <span class="na">name=</span><span class="s">"logstashDestination"</span> <span class="na">source=</span><span class="s">"logstash.destination"</span> <span class="na">defaultValue=</span><span class="s">"localhost:5044"</span> <span class="nt">/&gt;</span>
    <span class="nt">&lt;property</span> <span class="na">name=</span><span class="s">"LOG_FILE"</span> <span class="na">value=</span><span class="s">"application.log"</span><span class="nt">/&gt;</span>

    <span class="c">&lt;!-- Logstash로 전송할 Appender --&gt;</span>
    <span class="nt">&lt;appender</span> <span class="na">name=</span><span class="s">"LOGSTASH"</span> <span class="na">class=</span><span class="s">"net.logstash.logback.appender.LogstashTcpSocketAppender"</span><span class="nt">&gt;</span>
        <span class="nt">&lt;destination&gt;</span>${logstashDestination}<span class="nt">&lt;/destination&gt;</span>
        <span class="nt">&lt;encoder</span> <span class="na">class=</span><span class="s">"net.logstash.logback.encoder.LogstashEncoder"</span> <span class="nt">/&gt;</span>
    <span class="nt">&lt;/appender&gt;</span>

    <span class="c">&lt;!-- 콘솔 출력 --&gt;</span>
    <span class="nt">&lt;appender</span> <span class="na">name=</span><span class="s">"CONSOLE"</span> <span class="na">class=</span><span class="s">"ch.qos.logback.core.ConsoleAppender"</span><span class="nt">&gt;</span>
        <span class="nt">&lt;encoder&gt;</span>
            <span class="nt">&lt;pattern&gt;</span>%d{yyyy-MM-dd HH:mm:ss} %5p [${applicationName:-},%X{traceId:-},%X{spanId:-}] [%thread] %logger{36} - %msg%n<span class="nt">&lt;/pattern&gt;</span>
        <span class="nt">&lt;/encoder&gt;</span>
    <span class="nt">&lt;/appender&gt;</span>

    <span class="c">&lt;!-- 파일 출력 --&gt;</span>
    <span class="nt">&lt;appender</span> <span class="na">name=</span><span class="s">"FILE"</span> <span class="na">class=</span><span class="s">"ch.qos.logback.core.rolling.RollingFileAppender"</span><span class="nt">&gt;</span>
        <span class="nt">&lt;file&gt;</span>${LOG_FILE}<span class="nt">&lt;/file&gt;</span>
        <span class="nt">&lt;rollingPolicy</span> <span class="na">class=</span><span class="s">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span><span class="nt">&gt;</span>
            <span class="nt">&lt;fileNamePattern&gt;</span>application.%d{yyyy-MM-dd_HH-mm}.log.gz<span class="nt">&lt;/fileNamePattern&gt;</span>
            <span class="nt">&lt;maxHistory&gt;</span>2<span class="nt">&lt;/maxHistory&gt;</span>
        <span class="nt">&lt;/rollingPolicy&gt;</span>
        <span class="nt">&lt;encoder&gt;</span>
            <span class="nt">&lt;pattern&gt;</span>%d{yyyy-MM-dd HH:mm:ss} %5p [${applicationName:-},%X{traceId:-},%X{spanId:-}] [%thread] %logger{36} - %msg%n<span class="nt">&lt;/pattern&gt;</span>
        <span class="nt">&lt;/encoder&gt;</span>
    <span class="nt">&lt;/appender&gt;</span>

    <span class="c">&lt;!-- Logger 설정 --&gt;</span>
    <span class="nt">&lt;root</span> <span class="na">level=</span><span class="s">"info"</span><span class="nt">&gt;</span>
        <span class="nt">&lt;appender-ref</span> <span class="na">ref=</span><span class="s">"CONSOLE"</span> <span class="nt">/&gt;</span>
        <span class="nt">&lt;appender-ref</span> <span class="na">ref=</span><span class="s">"FILE"</span> <span class="nt">/&gt;</span>
        <span class="nt">&lt;appender-ref</span> <span class="na">ref=</span><span class="s">"LOGSTASH"</span> <span class="nt">/&gt;</span>
    <span class="nt">&lt;/root&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div></div>

<blockquote>
  <p>참고로 Logstash 의 기본 Port는 5044로 구동됩니다. 사이드 프로젝트에서 도커로 Logstash를 구동하여 실습을 진행했습니다.</p>
</blockquote>

<p>위 처럼 설정을 마치면 이제 스프링 애플리케이션의 로깅 시스템(Logback)이 자동으로 로그를 Logstash 로 전송할 것입니다.</p>

<h2 id="logstash---elasticsearch-로그-저장">Logstash -&gt; Elasticsearch 로그 저장</h2>

<p><code class="language-plaintext highlighter-rouge">Logstash</code>는 단순히 데이터 파이프라인 역할만 하기 때문에, 결국 로그를 저장할 데이터베이스가 필요합니다. 여기서 <code class="language-plaintext highlighter-rouge">Elasticsearch</code>가 로그를 저장하는 역할을 맡게 됩니다. 엘라스틱서치는 앞서 말했듯이, 대용량 로그 데이터를 빠르게 인덱싱 및 검색할 수 있습니다. 덕분에 찾고자 하는 로그를 빠르게 탐색할 수 있게 되는 것이죠.</p>

<p>아래는 Logstash의 설정 파일입니다. <code class="language-plaintext highlighter-rouge">애플리케이션 -&gt; Logstash (수집) -&gt; Elasticsearch (저장)</code>처럼 일련의 데이터 파이프라인의 설정 값입니다.  이를 Logstash를 구동시킬 때 설정해주어야 하는 값입니다.</p>

<div class="language-conf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input</span> {
    <span class="n">tcp</span> {
        <span class="n">port</span> =&gt; <span class="m">5044</span>
        <span class="n">codec</span> =&gt; <span class="n">json</span>
    }
}

<span class="n">output</span> {
    <span class="n">elasticsearch</span> {
        <span class="n">hosts</span> =&gt; [<span class="s2">"http://elasticsearch:9200"</span>]
        <span class="n">index</span> =&gt; <span class="s2">"application-logs-%{+YYYY.MM.dd}"</span>
    }
}
</code></pre></div></div>

<ul>
  <li><strong>input</strong>: 해당 설정으로 데이터를 입력받겠다는 정보를 나타냅니다. (TCP 5044, JSON 포맷으로 데이터 입력 받음.)</li>
  <li><strong>output</strong>: 출력하고자 하는 엘라스틱서치 저장소의 정보를 적어줍니다.
    <ul>
      <li><strong>hosts</strong>: 엘라스틱서치의 호스트 정보를 적어줍니다. 위 설정은 동일한 도커 네트워크 상에서 구동되고 있는 환경이기 때문에 도커 컨테이너명을 사용했습니다.</li>
      <li><strong>index</strong>: 엘라스틱서치의 어떤 인덱스에 저장할 지 명시해줍니다. (RDBMS의 테이블명이라고 보시면 됩니다.)</li>
    </ul>
  </li>
</ul>

<p>위 처럼 <code class="language-plaintext highlighter-rouge">logstash.conf</code> 파일을 설정했다면, 이제 <strong>Logstash가 수집한 로그 데이터를 Elasticsearch 저장소로 전송</strong>할 것입니다.</p>

<p>만약, Logstash를 도커로 구동하신다면 아래 도커 컴포즈 파일처럼 <code class="language-plaintext highlighter-rouge">logstash.conf</code> 파일을 볼륨 마운팅 해주셔야 합니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3'</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">logstash</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">docker.elastic.co/logstash/logstash:8.10.0</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">logstash</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">5044:5044"</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">./logstash.conf:/usr/share/logstash/pipeline/logstash.conf</span>
</code></pre></div></div>

<h2 id="elasticsearch---kibana-로그-데이터-시각화">Elasticsearch -&gt; Kibana 로그 데이터 시각화</h2>

<p>이제 <code class="language-plaintext highlighter-rouge">Elasticsearch</code>에 로그 데이터가 적재된다면, Kibana를 활용하여 로그 데이터를 시각화할 수 있습니다.</p>

<p>이때 <code class="language-plaintext highlighter-rouge">Zipkin</code>을 활용한 분산 로그 트레이싱을 통합 적용한다면, 여러 서비스에 걸쳐 처리될 때 발생하는 로그의 흐름을 추적할 수 있도록 도와줍니다. 각 요청에 <strong>고유한 TraceID를 부여</strong>하여, 여러 서비스에 분산되어 기록된 로그들을 <strong>Elasticsearch에서 하나의 흐름으로 연결지어 검색</strong>할 수 있습니다.</p>

<p>Kibana의 Discovery 서비스에서 <strong>TraceID</strong>를 입력하면 해당 요청에 관련된 모든 로그가 타임스탬프 순서대로 정렬시켜 모니터링 할 수 있습니다. 이를 통해 단일 요청이 서비스 전반에서 어떻게 처리되었는지 한눈에 파악할 수 있게 됩니다.</p>

<figure align="center">
<img src="/post_images/spring-cloud-side-project/logs-discovery.png" />
<figcaption></figcaption>
</figure>

<p>또한, 로그 레벨의 분류를 통해 전체 로그에 대한 통계를 대시보드로 확인도 가능합니다.</p>

<figure align="center">
<img src="/post_images/spring-cloud-side-project/logs-dashboard.png" />
<figcaption></figcaption>
</figure>

<h1 id="-결론">🚀 결론</h1>

<p>ELK 스택을 기반으로 한 중앙 집중식 로그 모니터링은 MSA 환경에서 필수적인 요소라고 생각합니다. 분산된 로그를 한눈에 파악할 수 없는 문제를 해결해주고, 실시간 모니터링 대응 능력을 향상시켜줌과 동시에, Zipkin과의 통합을 통해 요청의 전체 흐름을 추적할 수 있다는 점은 시스템 운영의 효율성을 크게 향상시킬 수 있습니다. ELK스택과 Zipkin과 같은 도구들을 적절히 활용한다면, 장애 발생 시 빠른 원인 분석과 문제 해결이 가능해져, 전체 서비스의 안정성 유지에 기여할 수 있을 것입니다.</p>

<p>이상으로 ELK 스택과 Zipkin 통합을 통한 중앙 집중식 로그 모니터링의 필요성과 장점에 대해 알아보았습니다. 본 포스트를 참고하여 여러분의 환경에 맞는 최적의 로그 관리 시스템 구축에 도움이 되었으면 좋겠습니다. 감사합니다.</p>

<h1 id="-참고-자료">📂 참고 자료</h1>

<ul>
  <li><a href="https://www.inflearn.com/course/%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%97%90%EA%B2%8C-%ED%95%84%EC%9A%94%ED%95%9C-%EB%A1%9C%EA%B7%B8%EA%B4%80%EB%A6%AC">인프런 - 개발자에게 필요한 로그 관리</a></li>
  <li><a href="https://engineering.linecorp.com/ko/blog/line-ads-msa-opentracing-zipkin">LINE 광고 플랫폼의 MSA 환경에서 Zipkin을 활용해 로그 트레이싱하기</a></li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="MSA" /><category term="ELK" /><category term="Elatsticsearch" /><category term="Logstash" /><category term="Kibana" /><category term="Logback" /><category term="Zipkin" /><summary type="html"><![CDATA[마이크로서비스 아키텍처에서 ELK(Elasticsearch + Logstash + Kibana) 스택을 활용한 중앙 집중식 로그 모니터링에 대해 알아봅시다!]]></summary></entry><entry><title type="html">Zipkin을 활용한 마이크로서비스 분산 트레이싱</title><link href="http://localhost:4000/spring%20cloud/zipkin/msa/2025/02/23/Zipkin-Distributed-Tracing/" rel="alternate" type="text/html" title="Zipkin을 활용한 마이크로서비스 분산 트레이싱" /><published>2025-02-23T00:00:00+09:00</published><updated>2025-02-23T00:00:00+09:00</updated><id>http://localhost:4000/spring%20cloud/zipkin/msa/2025/02/23/Zipkin-Distributed-Tracing</id><content type="html" xml:base="http://localhost:4000/spring%20cloud/zipkin/msa/2025/02/23/Zipkin-Distributed-Tracing/"><![CDATA[<blockquote>
  <p>분산 환경에서 Zipkin을 활용한 요청의 전체 흐름을 추적해봅시다!</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">📌 들어가기</h1>

<p>마이크로서비스 아키텍처는 독립적으로 배포되고 관리되는 작은 서비스들이 모여 애플리케이션을 구성하게 됩니다. 이러한 환경에서는 서비스 간의 통신이 빈번하게 발생하며, 각 서비스가 독자적인 로그를 남기기 때문에 전체 트랜잭션의 흐름을 파악하기가 어렵습니다. 예를 들어, 주문 서비스 -&gt; 결제 서비스 -&gt; 배송 서비스 등의 여러 서비스가 순차적으로 호출되는 과정에서 각 서비스는 별도의 로그를 각자 남기기 때문에 어떤 서비스에서 문제가 발생했는지 확인하기 어렵습니다.</p>

<p>이러한 문제점 때문에 <strong>분산 트레이싱</strong>은 문제 발생 시 원인을 신속하게 파악하고, 성능 병목을 찾아내는 데 필수적인 도구로 등장합니다.</p>

<p>본 포스트에서는 분산 트레이싱 도구 중 <code class="language-plaintext highlighter-rouge">Zipkin</code>을 활용한 분산 트레이싱을 다루도록 하겠습니다.</p>

<h1 id="마이크로서비스-환경의-복잡성">마이크로서비스 환경의 복잡성</h1>

<p>마이크로서비스 아키텍처에서는 <strong>하나의 사용자 요청이 여러 서비스를 거치며 처리</strong>됩니다. 주문, 결제, 배송 서비스 등 여러 서비스를 거치게 되는 것이죠. 이러한 <strong>분산된 호출 구조</strong>는 여러 <strong>문제점</strong>을 유발할 수 있습니다.</p>

<p>각 서비스마다 <strong>별도의 로그</strong>를 남기기 때문에 하나의 트랜잭션이 어디에서 지연되거나 장애가 발생했는지 확인하기 어렵습니다. 그리고 전체 흐름에서 어느 부분이 응답 시간을 지연시키는지도 파악하기 어렵습니다.</p>

<p><strong>모놀리식(Monolihic)</strong>의 경우 하나의 서비스로 애플리케이션이 구동되기 때문에, 전체 흐름에 대한 로그를 하나의 서비스에서 디버깅 할 수 있습니다. 하지만 <strong>MSA</strong>에서는 문제를 파악하기 위해 관련된 모든 서비스들의 로그를 하나하나 다 살펴봐야 하는 번거로움이 존재합니다.</p>

<p>만약 분산 트레이싱 도구가 없다면, 위와 같은 문제를 해결하기 위해 각 서비스에서 개별적으로 로그를 분석해야 하며, 이는 시간 소모적이이고 비효율적일 뿐만 아니라, 문제 진단의 어려움이 따르기 때문에 신속하게 대응하지 못할 위험이 높아집니다.</p>

<h1 id="zipkin을-활용한-요청-추적">Zipkin을 활용한 요청 추적</h1>

<p><code class="language-plaintext highlighter-rouge">Zipkin</code>은 <strong>오픈 소스 분산 트레이싱 시스템</strong>으로, 마이크로서비스 환경에서 서비스 간 호출 흐름을 <strong>시각화하고 분석할 수 있도록 도와주는 도구</strong>입니다. <code class="language-plaintext highlighter-rouge">Zipkin</code>을 활용하면 각 서비스의 호출 데이터를 중앙에서 수집하여 아래 문제점들을 해결해줍니다.</p>

<ol>
  <li><strong>전체 호출 흐름 시각화</strong>: 사용자 요청이 어떤 경로로 전달되는지 시각화하여 한 눈에 파악 할수 있도록 해줍니다.</li>
  <li><strong>Latency 분석</strong>: 각 서비스 간 호출의 응답 시간 정보를 제공하여 어떤 서비스의 어떤 로직에서 성능 병목이 일어나는지 쉽게 식별할 수 있습니다.</li>
  <li><strong>장애 원인 분석</strong>: 트랜잭션 중 발생한 예외나 오류를 신속하게 탐지하고, 어느 서비스에서 문제가 발생했는지 분석 할 수 있습니다.</li>
</ol>

<h1 id="zipkin-적용-방법">Zipkin 적용 방법</h1>

<p>예전에는 Spring Boot 애플리케이션에 쉽게 분산 트레이싱 기능을 추가할 수 있도록 도와주는 <code class="language-plaintext highlighter-rouge">Spring Cloud Sleuth</code>라는 라이브러리를 사용했었습니다. 하지만 최근 버전으로 업데이트 되면서 <code class="language-plaintext highlighter-rouge">Spring Cloud Sleuth</code>는 Deprecated 될 라이브러리가 되었습니다. 따라서 최근 버전에서는 <code class="language-plaintext highlighter-rouge">Micrometer</code>로 분산 트레이싱 기능을 추가하도록 변경되었습니다.</p>

<h2 id="dependency">Dependency</h2>

<div class="language-groovy highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">implementation</span> <span class="s1">'org.springframework.boot:spring-boot-starter-actuator'</span>
<span class="n">implementation</span> <span class="s1">'io.micrometer:micrometer-observation'</span>
<span class="n">implementation</span> <span class="s1">'io.micrometer:micrometer-tracing-bridge-brave'</span>
<span class="n">implementation</span> <span class="s1">'io.zipkin.brave:brave-instrumentation-spring-web'</span>
<span class="n">implementation</span> <span class="s1">'io.zipkin.reporter2:zipkin-reporter-brave'</span>
</code></pre></div></div>

<h2 id="applicationyml">application.yml</h2>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">spring</span><span class="pi">:</span>
  <span class="na">application</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">product-service</span>
<span class="na">management</span><span class="pi">:</span>
  <span class="na">tracing</span><span class="pi">:</span>
    <span class="na">sampling</span><span class="pi">:</span>
      <span class="na">probability</span><span class="pi">:</span> <span class="m">1.0</span>
    <span class="na">propagation</span><span class="pi">:</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">b3</span>
  <span class="na">zipkin</span><span class="pi">:</span>
    <span class="na">tracing</span><span class="pi">:</span>
      <span class="na">endpoint</span><span class="pi">:</span> <span class="s">${MANAGEMENT_ZIPKIN_TRACING_ENDPOINT:http://localhost:9411/api/v2/spans}</span>
</code></pre></div></div>

<ul>
  <li>여기서 <code class="language-plaintext highlighter-rouge">spring.application.name</code>은 서비스 태깅에 활용되며, 각 서비스의 이름이 <strong>Zipkin UI</strong>에 표시되어 호출 흐름을 쉽게 파악할 수 있습니다.</li>
  <li>위와 같이 의존성과 설정을 마치면, 자동으로 <strong>각 요청에 고유한 Trace ID와 Span ID를 부여하여, 서비스 간의 호출 관계를 추적</strong>하게 됩니다.</li>
</ul>

<h1 id="zipkin-ui를-활용한-트레이스-분석">Zipkin UI를 활용한 트레이스 분석</h1>

<h2 id="서비스-간-호출-흐름-시각화">서비스 간 호출 흐름 시각화</h2>

<p><strong>Zipkin UI</strong>는 수집된 트레이스 데이터를 기반으로, 서비스 간 호출 흐름을 직관적으로 시각화해줍니다. 개발자는 UI를 통해 각 서비스가 호출한 순서와 관계를 그래픽으로 확인할 수 있습니다. 또한 특정 트랜잭션의 세부적인 스팬 정보와 타임라인을 분석할 수도 있습니다.</p>

<h2 id="latency-분석-및-장애-감지">Latency 분석 및 장애 감지</h2>

<p>Zipkin UI에서는 각 스팬의 응답 시간을 시각적으로 표시하여, 어느 부분에서 지연이 발생했는지 쉽게 식별할 수 있습니다. 이를 통해 성능 병목 구간을 찾아내고, 장애 발생 시 원인 분석에 필요한 정보를 제공합니다. 만약 이러한 시각화 도구가 없으면, 로그 파일만으로 각 서비스 간의 호출 관계와 지연 시간을 분석해야 하므로, 문제 발생 시 즉각적인 대응이 어려워질 것입니다.</p>

<h1 id="spring-aop를-활용한-미들웨어-간의-요청-추적">Spring AOP를 활용한 미들웨어 간의 요청 추적</h1>

<p>마이크로서비스에서는 HTTP 호출 외에도 <strong>Kafka</strong>, <strong>Redis와</strong> 같은 미들웨어를 활용하는 경우가 많습니다. Zipkin과 Micrometer의 기본 의존성과 설정만으로는 미들웨어 통신 경로를 자동 추적하진 않습니다. 미들웨어간의 호출 흐름까지 추적하기 위해, 추적에 필요한 로직을 <strong>스프링 AOP</strong>를 활용하여 <strong>사용자 정의 트레이싱</strong> 코드를 삽입할 수 있었습니다.</p>

<p>예를 들어, 스프링 AOP를 활용하여 <strong>Kafka</strong>를 통한 메시지 발행/구독 흐름도 추적할 수 있습니다. 이를 통해 메시지 큐를 통한 비동기 호출도 명확하게 추적할 수 있으며, 메시지 손실이나 지연 문제를 쉽게 추적할 수 있습니다.</p>

<p>만약 이러한 미들웨어 추적 메커니즘이 없다면, 각 미들웨어 간의 호출 흐름이 단절되어 문제 발생 시 원인 파악에 큰 어려움이 따를 것입니다. 이는 디버깅 하는 시간이 급격히 증가할 수 있습니다.</p>

<h1 id="server--kafka-메시지-트레이싱">Server → Kafka 메시지 트레이싱</h1>

<p>이제, 실제로 사이드 프로젝트에서 <strong>Spring AOP</strong>를 활용하여 <strong>Zipkin B3 트레이싱</strong>을 <strong>Kafka</strong> 메시지에 적용하는 방법을 살펴보겠습니다.</p>

<p>스프링 애플리케이션에서 <strong>Kafka</strong>로 메시지를 발행할 때, 현재의 트레이싱 컨텍스트를 메시지 헤더에 포함시켜 전달하는 것이 중요합니다. 이를 위해 <strong>AOP(Aspect-Oriented Programming)</strong>를 활용하면 기존 코드를 수정하지 않고도 이 기능을 깔끔하게 추가할 수 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">KafkaTemplate.send(String, Object)</code> 메서드를 인터셉트하여 <strong>ProducerRecord</strong>에 <strong>B3 헤더</strong>를 추가하는 방식으로 트레이싱 컨텍스트를 전파할 수 있습니다. 이렇게 하면 <strong>Kafka</strong> 소비자가 메시지를 처리할 때 동일한 트레이싱 컨텍스트를 유지할 수 있어, <strong>Zipkin</strong>에서 전체 요청 흐름을 연속적으로 확인할 수 있게 됩니다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Aspect</span>
<span class="nd">@Component</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">B3PropagationAspect</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Tracer</span> <span class="n">tracer</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">B3PropagationAspect</span><span class="o">(</span><span class="nc">Tracer</span> <span class="n">tracer</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">tracer</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="nd">@Around</span><span class="o">(</span><span class="s">"execution(* org.springframework.kafka.core.KafkaTemplate.send(String, ..))"</span><span class="o">)</span>
    <span class="kd">public</span> <span class="nc">Object</span> <span class="nf">addB3HeadersToProducerMessage</span><span class="o">(</span><span class="nc">ProceedingJoinPoint</span> <span class="n">joinPoint</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Throwable</span> <span class="o">{</span>
        <span class="nc">Object</span><span class="o">[]</span> <span class="n">args</span> <span class="o">=</span> <span class="n">joinPoint</span><span class="o">.</span><span class="na">getArgs</span><span class="o">();</span>

        <span class="c1">// 메서드 시그니처: send(String topic, V data)</span>
        <span class="nc">String</span> <span class="n">topic</span> <span class="o">=</span> <span class="o">(</span><span class="nc">String</span><span class="o">)</span> <span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">];</span>
        <span class="nc">String</span> <span class="n">data</span> <span class="o">=</span> <span class="o">(</span><span class="nc">String</span><span class="o">)</span> <span class="n">args</span><span class="o">[</span><span class="mi">1</span><span class="o">];</span>

        <span class="c1">// ProducerRecord 생성</span>
        <span class="nc">ProducerRecord</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">record</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ProducerRecord</span><span class="o">&lt;&gt;(</span><span class="n">topic</span><span class="o">,</span> <span class="n">data</span><span class="o">);</span>

        <span class="c1">// 현재 활성화된 Span에서 b3 헤더에 필요한 값 추출</span>
        <span class="nc">Span</span> <span class="n">currentSpan</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="na">currentSpan</span><span class="o">();</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">currentSpan</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">record</span><span class="o">.</span><span class="na">headers</span><span class="o">().</span><span class="na">add</span><span class="o">(</span><span class="s">"X-B3-TraceId"</span><span class="o">,</span> <span class="n">currentSpan</span><span class="o">.</span><span class="na">context</span><span class="o">().</span><span class="na">traceIdString</span><span class="o">().</span><span class="na">getBytes</span><span class="o">(</span><span class="no">UTF_8</span><span class="o">));</span>
            <span class="n">record</span><span class="o">.</span><span class="na">headers</span><span class="o">().</span><span class="na">add</span><span class="o">(</span><span class="s">"X-B3-SpanId"</span><span class="o">,</span> <span class="n">currentSpan</span><span class="o">.</span><span class="na">context</span><span class="o">().</span><span class="na">spanIdString</span><span class="o">().</span><span class="na">getBytes</span><span class="o">(</span><span class="no">UTF_8</span><span class="o">));</span>
            <span class="nc">String</span> <span class="n">sampled</span> <span class="o">=</span> <span class="o">(</span><span class="n">currentSpan</span><span class="o">.</span><span class="na">context</span><span class="o">().</span><span class="na">sampled</span><span class="o">()</span> <span class="o">!=</span> <span class="kc">null</span> <span class="o">&amp;&amp;</span> <span class="n">currentSpan</span><span class="o">.</span><span class="na">context</span><span class="o">().</span><span class="na">sampled</span><span class="o">())</span> <span class="o">?</span> <span class="s">"1"</span> <span class="o">:</span> <span class="s">"0"</span><span class="o">;</span>
            <span class="n">record</span><span class="o">.</span><span class="na">headers</span><span class="o">().</span><span class="na">add</span><span class="o">(</span><span class="s">"X-B3-Sampled"</span><span class="o">,</span> <span class="n">sampled</span><span class="o">.</span><span class="na">getBytes</span><span class="o">(</span><span class="no">UTF_8</span><span class="o">));</span>
        <span class="o">}</span>

        <span class="c1">// 원래의 KafkaTemplate.send(String, V) 대신,</span>
        <span class="c1">// ProducerRecord를 인자로 받는 send 메서드를 호출하여 메시지 전송</span>
        <span class="nc">KafkaTemplate</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">kafkaTemplate</span> <span class="o">=</span> <span class="o">(</span><span class="nc">KafkaTemplate</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;)</span> <span class="n">joinPoint</span><span class="o">.</span><span class="na">getTarget</span><span class="o">();</span>

        <span class="nc">Span</span> <span class="n">newSpan</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="na">nextSpan</span><span class="o">().</span><span class="na">name</span><span class="o">(</span><span class="n">joinPoint</span><span class="o">.</span><span class="na">getSignature</span><span class="o">().</span><span class="na">toString</span><span class="o">()).</span><span class="na">start</span><span class="o">();</span>
        <span class="k">try</span> <span class="o">(</span><span class="nc">Tracer</span><span class="o">.</span><span class="na">SpanInScope</span> <span class="n">ws</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="na">withSpanInScope</span><span class="o">(</span><span class="n">newSpan</span><span class="o">.</span><span class="na">start</span><span class="o">()))</span> <span class="o">{</span>
            <span class="k">return</span> <span class="n">kafkaTemplate</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">record</span><span class="o">);</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Throwable</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">newSpan</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="n">e</span><span class="o">);</span>
            <span class="k">throw</span> <span class="n">e</span><span class="o">;</span>
        <span class="o">}</span> <span class="k">finally</span> <span class="o">{</span>
            <span class="n">newSpan</span><span class="o">.</span><span class="na">finish</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ol>
  <li>Spring의 <code class="language-plaintext highlighter-rouge">@Aspect</code> 기능을 활용하여 <code class="language-plaintext highlighter-rouge">KafkaTemplate.send(String, ..)</code> 메서드 호출을 인터셉트합니다. 이를 통해 메시지가 <strong>Kafka</strong>로 전송되기 직전에 트레이싱 정보를 주입할 수 있는 지점을 확보합니다.</li>
  <li>인터셉트 시점에 <strong>Brave Tracer API</strong>를 통해 현재 활성화된 트레이싱 컨텍스트(<strong>TraceId, SpanId, Sampling</strong> 여부 등)를 추출하고, 이를 Kafka의 <strong>ProducerRecord</strong> 헤더에 B3 형식(<strong>X-B3-TraceId, X-B3-SpanId, X-B3-Sampled</strong>)으로 인코딩하여 추가합니다.</li>
  <li>이렇게 트레이싱 정보가 포함된 메시지를 소비자 서비스에서 처리할 때, 메시지 헤더에서 B3 정보를 추출하여 동일한 트레이싱 컨텍스트를 복원합니다. 이를 통해 Zipkin과 같은 분산 트레이싱 시스템에서 서비스 간 경계를 넘어 하나의 연속된 트랜잭션으로 시각화하고 분석할 수 있게 됩니다.</li>
</ol>

<p>⭐️ 이 방식의 가장 큰 장점은 애플리케이션 코드를 직접 수정하지 않고도 트레이싱 컨텍스트 전파를 구현할 수 있어, <strong>관심사 분리(Separation of Concerns)</strong> 원칙을 준수하면서 분산 시스템의 가시성을 높일 수 있다는 점입니다.</p>

<h1 id="kafka--server-트레이싱">Kafka → Server 트레이싱</h1>

<p><strong>Kafka</strong> 메시지를 소비하는 측에서는 메시지 헤더에 포함된 <strong>B3 트레이싱</strong> 정보를 추출하여 서버 처리 과정의 트레이싱에 연결해야 합니다. 이 과정 역시 <strong>AOP</strong>를 활용하면 깔끔하게 구현할 수 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">@KafkaListener</code> 어노테이션이 적용된 메서드를 인터셉트하여 <strong>ConsumerRecord</strong>에서 <strong>B3 헤더</strong> 정보를 추출하고, 이를 기반으로 새로운 스팬을 생성하는 방식으로 구현됩니다. 이렇게 하면 소비자 서비스에서의 처리 과정이 기존 트레이싱 컨텍스트와 연결되어 하나의 흐름으로 추적됩니다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Aspect</span>
<span class="nd">@Component</span>
<span class="nd">@Slf4j</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">KafkaListenerTracingAspect</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Tracing</span> <span class="n">tracing</span><span class="o">;</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Tracer</span> <span class="n">tracer</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">KafkaListenerTracingAspect</span><span class="o">(</span><span class="nc">Tracing</span> <span class="n">tracing</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">tracing</span> <span class="o">=</span> <span class="n">tracing</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">tracer</span> <span class="o">=</span> <span class="n">tracing</span><span class="o">.</span><span class="na">tracer</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="cm">/**
     * KafkaListener를 감싸서, ConsumerRecord에 담긴 b3 헤더로부터 trace context를 추출하고
     * 해당 context 기반의 스팬을 생성하여 로그 MDC에 반영합니다.
     */</span>
    <span class="nd">@Around</span><span class="o">(</span><span class="s">"@annotation(org.springframework.kafka.annotation.KafkaListener)"</span><span class="o">)</span>
    <span class="kd">public</span> <span class="nc">Object</span> <span class="nf">aroundKafkaListener</span><span class="o">(</span><span class="nc">ProceedingJoinPoint</span> <span class="n">joinPoint</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Throwable</span> <span class="o">{</span>
        <span class="nc">ConsumerRecord</span><span class="o">&lt;?,</span> <span class="o">?&gt;</span> <span class="n">consumerRecord</span> <span class="o">=</span> <span class="n">extractConsumerRecord</span><span class="o">(</span><span class="n">joinPoint</span><span class="o">.</span><span class="na">getArgs</span><span class="o">());</span>

        <span class="nc">Span</span> <span class="n">newSpan</span><span class="o">;</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">consumerRecord</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="c1">// b3 헤더 추출을 위한 extractor 람다 (key에 해당하는 헤더 값을 문자열로 변환)</span>
            <span class="nc">TraceContextOrSamplingFlags</span> <span class="n">extracted</span> <span class="o">=</span> <span class="n">tracing</span><span class="o">.</span><span class="na">propagation</span><span class="o">().</span><span class="na">extractor</span><span class="o">(</span>
                    <span class="o">(</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">kafka</span><span class="o">.</span><span class="na">common</span><span class="o">.</span><span class="na">header</span><span class="o">.</span><span class="na">Headers</span> <span class="n">headers</span><span class="o">,</span> <span class="nc">String</span> <span class="n">key</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">{</span>
                        <span class="nc">Header</span> <span class="n">header</span> <span class="o">=</span> <span class="n">headers</span><span class="o">.</span><span class="na">lastHeader</span><span class="o">(</span><span class="n">key</span><span class="o">);</span>
                        <span class="k">return</span> <span class="n">header</span> <span class="o">!=</span> <span class="kc">null</span> <span class="o">?</span> <span class="k">new</span> <span class="nc">String</span><span class="o">(</span><span class="n">header</span><span class="o">.</span><span class="na">value</span><span class="o">(),</span> <span class="nc">StandardCharsets</span><span class="o">.</span><span class="na">UTF_8</span><span class="o">)</span> <span class="o">:</span> <span class="kc">null</span><span class="o">;</span>
                    <span class="o">}</span>
            <span class="o">).</span><span class="na">extract</span><span class="o">(</span><span class="n">consumerRecord</span><span class="o">.</span><span class="na">headers</span><span class="o">());</span>

            <span class="c1">// 추출된 context가 있다면 이를 기반으로 자식 스팬 생성</span>
            <span class="n">newSpan</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="na">nextSpan</span><span class="o">(</span><span class="n">extracted</span><span class="o">).</span><span class="na">name</span><span class="o">(</span><span class="n">joinPoint</span><span class="o">.</span><span class="na">getSignature</span><span class="o">().</span><span class="na">toShortString</span><span class="o">());</span>
        <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
            <span class="c1">// ConsumerRecord가 없으면 단순히 새 스팬 생성</span>
            <span class="n">newSpan</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="na">nextSpan</span><span class="o">().</span><span class="na">name</span><span class="o">(</span><span class="n">joinPoint</span><span class="o">.</span><span class="na">getSignature</span><span class="o">().</span><span class="na">toShortString</span><span class="o">());</span>
        <span class="o">}</span>

        <span class="k">try</span> <span class="o">(</span><span class="nc">Tracer</span><span class="o">.</span><span class="na">SpanInScope</span> <span class="n">ws</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="na">withSpanInScope</span><span class="o">(</span><span class="n">newSpan</span><span class="o">.</span><span class="na">start</span><span class="o">()))</span> <span class="o">{</span>
            <span class="c1">// 스팬이 활성화된 상태에서 대상 메서드 실행: 이때 MDC에 TraceId 등이 반영되어 로그에 출력됨</span>
            <span class="k">return</span> <span class="n">joinPoint</span><span class="o">.</span><span class="na">proceed</span><span class="o">();</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Throwable</span> <span class="n">t</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">newSpan</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="n">t</span><span class="o">);</span>
            <span class="k">throw</span> <span class="n">t</span><span class="o">;</span>
        <span class="o">}</span> <span class="k">finally</span> <span class="o">{</span>
            <span class="n">newSpan</span><span class="o">.</span><span class="na">finish</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="nc">ConsumerRecord</span><span class="o">&lt;?,</span> <span class="o">?&gt;</span> <span class="n">extractConsumerRecord</span><span class="o">(</span><span class="nc">Object</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">args</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">for</span> <span class="o">(</span><span class="nc">Object</span> <span class="n">arg</span> <span class="o">:</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
                <span class="k">if</span> <span class="o">(</span><span class="n">arg</span> <span class="k">instanceof</span> <span class="nc">ConsumerRecord</span><span class="o">)</span> <span class="o">{</span>
                    <span class="k">return</span> <span class="o">(</span><span class="nc">ConsumerRecord</span><span class="o">&lt;?,</span> <span class="o">?&gt;)</span> <span class="n">arg</span><span class="o">;</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="kc">null</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>
<p>이 <strong>Aspect</strong>는 다음과 같은 핵심 기능을 수행합니다:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">@KafkaListener</code> 어노테이션이 적용된 메서드를 타겟으로 하는 <strong>Pointcut</strong> 정의</li>
  <li><strong>ConsumerRecord</strong> 객체에서 B3 헤더 추출을 위한 커스텀 <strong>extractor</strong> 구현</li>
  <li>추출된 트레이싱 컨텍스트를 기반으로 새로운 스팬 생성</li>
  <li>생성된 스팬의 컨텍스트 내에서 원래 메서드 실행</li>
  <li>메서드 실행 중 발생하는 예외를 스팬에 기록</li>
  <li>메서드 실행 완료 후 스팬 종료</li>
</ol>

<p>이러한 방식으로 구현하면, <strong>Kafka</strong> 메시지 소비 시점에서 자동으로 트레이싱 컨텍스트가 복원되어 <strong>MDC(Mapped Diagnostic Context)</strong>에 반영됩니다. 이를 통해 로그에 <strong>traceId</strong>가 자동으로 포함되어 로그 추적이 용이해지며, <strong>Zipkin</strong>과 같은 분산 트레이싱 시스템에서도 하나의 트랜잭션으로 시각화됩니다.</p>

<p>참고로, <strong>ELK 스택을 이용한 중앙집중식 로그 모니터링 시스템</strong>에 관한 <a href="https://seung-il-bang.github.io/msa/elk/2025/02/24/ELK-Stack-Log-Analysis/" target="_blank">포스트</a>도 있습니다. 짧게 소개하자면, <strong>Kibana</strong>에서 <strong>TraceId</strong>를 검색하면 여러 서버에서 분산적으로 발생한 로그 전부를 <strong>타임스탬프(timestamp)순</strong>으로 확인할 수 있습니다.</p>

<p>아래 이미지는 <strong>주문 생성</strong>, <strong>결제 승인</strong>, <strong>배달 접수</strong>, <strong>주문 완료</strong> 등 여러 이벤트 처리에 대한 <strong>kafka 비동기 처리</strong> 도입에도 <strong>사용자의 한 요청에 대한 모든 흐름이 트레이싱</strong> 되고 있는 것을 확인할 수 있었습니다:</p>

<figure align="center">
<img src="/post_images/spring-cloud-side-project/zipkin-tracing.png" />
<figcaption></figcaption>
</figure>

<p><code class="language-plaintext highlighter-rouge">user service</code>, <code class="language-plaintext highlighter-rouge">order service</code>, <code class="language-plaintext highlighter-rouge">product service</code>, <code class="language-plaintext highlighter-rouge">delivery service</code>, <code class="language-plaintext highlighter-rouge">payment service</code> 각 서버마다 이벤트 발행과 구독을 처리하는 흐름이 모두 담겨 있습니다.</p>

<h1 id="트레이싱-컨텍스트-전파의-이점">트레이싱 컨텍스트 전파의 이점</h1>

<p>이러한 방식으로 트레이싱 컨텍스트를 전파함으로써 얻을 수 있는 주요 이점은 다음과 같습니다:</p>

<ol>
  <li><strong>End-to-End 가시성</strong>: 사용자 요청부터 모든 서비스를 거쳐 최종 응답까지의 전체 흐름을 하나의 트레이스로 확인 가능</li>
  <li><strong>성능 병목 식별</strong>: 전체 트랜잭션에서 지연이 발생하는 지점을 정확히 식별 가능</li>
  <li><strong>장애 추적 용이성</strong>: 오류 발생 시 관련된 모든 서비스의 로그를 쉽게 연관지어 분석 가능</li>
  <li><strong>코드 침습성 최소화</strong>: AOP를 활용하여 비즈니스 로직과 트레이싱 로직의 명확한 분리 유지</li>
</ol>

<p>이러한 접근 방식은 마이크로서비스 아키텍처에서 특히 유용하며, 서비스 간 메시지 전달이 빈번한 <strong>분산 시스템의 관찰성(Observability)을 크게 향상</strong>시킵니다.</p>

<h1 id="-결론">🚀 결론</h1>

<p>마이크로서비스 아키텍처에서는 서비스 간 호출 흐름이 복잡해짐에 따라, 단순 로그 분석만으로는 문제의 원인을 파악하기 어렵습니다. <code class="language-plaintext highlighter-rouge">Zipkin</code>과 <code class="language-plaintext highlighter-rouge">Micrometer</code>를 활용하면, 전체 트랜잭션의 흐름을 시각화하고 각 서비스의 성능을 모니터링할 수 있어 문제 발생 시 신속하게 대응할 수 있습니다. 이러한 도구들이 없다면, 시스템 장애나 성능 병목을 찾아내는 데에 많은 시간과 리소스가 소모되며, 이는 비즈니스에 심각한 영향을 미칠 것입니다. MSA 환경에서 <code class="language-plaintext highlighter-rouge">Zipkin</code>을 통한 <strong>분산 트레이싱</strong>은 단순히 로그를 남기는 것을 넘어, 시스템의 <strong>전체적인 건강 상태를 관리</strong>하고, 장애 발생 시 <strong>신속한 원인 분석 및 대응</strong> 전략을 마련하는 데 <strong>필수적인 요소</strong>라 볼 수 있습니다.</p>

<h1 id="참고-자료">참고 자료</h1>

<ul>
  <li><a href="https://engineering.linecorp.com/ko/blog/line-ads-msa-opentracing-zipkin">LINE 광고 플랫폼의 MSA 환경에서 Zipkin을 활용해 로그 트레이싱하기</a></li>
  <li><a href="https://github.com/openzipkin/b3-propagation">b3-propagation</a></li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="Spring Cloud" /><category term="Zipkin" /><category term="MSA" /><category term="Distributed Tracing" /><category term="b3 propagation" /><category term="Micrometer" /><summary type="html"><![CDATA[분산 환경에서 Zipkin을 활용한 요청의 전체 흐름을 추적해봅시다!]]></summary></entry><entry><title type="html">Redisson을 활용한 분산 락 그리고 AOP 적용</title><link href="http://localhost:4000/msa/redis/2025/02/22/Redisson-Lock-and-AOP/" rel="alternate" type="text/html" title="Redisson을 활용한 분산 락 그리고 AOP 적용" /><published>2025-02-22T00:00:00+09:00</published><updated>2025-02-22T00:00:00+09:00</updated><id>http://localhost:4000/msa/redis/2025/02/22/Redisson-Lock-and-AOP</id><content type="html" xml:base="http://localhost:4000/msa/redis/2025/02/22/Redisson-Lock-and-AOP/"><![CDATA[<blockquote>
  <p>분산 시스템에서 Redis를 이용한 분산 락의 필요성과 분산 락 적용 부분의 AOP 활용 방법을 알아봅시다.</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">📌 들어가기</h1>

<p>MSA와 같은 분산 시스템에서는 여러 인스턴스가 동시에 하나의 리소스에 접근하는 경우가 빈번하게 발생할 수 있습니다. 예를 들어, 주문이 동시다발적으로 발생하여 상품의 재고를 차감하기 위해 여러 인스턴스가 재고에 접근하는 경우가 그렇습니다.</p>

<p>이때 동시성 이슈가 발생하여 데이터 무결성에 문제가 발생합니다. 이를 방지하기 위해 분산 락(Distributed Lock)이 필요한 것입니다.</p>

<p>본 포스트에서는 Redis기반의 <strong>분산 락</strong>을 구현하기 위해 <strong>Redisson</strong>라이브러리를 활용하는 방법과, <strong>스프링 AOP(Aspect Oriented Programming)</strong>를 통해 락 처리 로직을 분리하여 코드의 응집도와 유지보수성을 높이는 방법을 살펴보도록 하겠습니다.</p>

<h1 id="redis-라이브러리-redisson을-활용한-분산-락">Redis 라이브러리: Redisson을 활용한 분산 락</h1>

<p>Redis는 인메모리 데이터 저장소로 높은 성능과 빠른 응답 속도를 제공합니다. 이를 활용하여 여러 프로세스 혹은 서버 간에 분산 락을 구현할 수 있으며, 분산 환경에서의 동시성 제어와 데이터 무결성 확보에 큰 역할을 하게 됩니다.</p>

<p><strong>Redisson</strong>은 Redis를 Java 애플리케이션에서 쉽게 사용할 수 있도록 지원하는 <strong>Redis 클라이언트 라이브러리</strong>입니다. Redisson은 분산 락, 세마포어 등 여러 동시성 관련 기능을 제공하며, <strong>복잡한 락 로직을 단순화</strong>시켜 줍니다.</p>

<h1 id="lettuce-vs-redisson">Lettuce vs Redisson</h1>

<p><code class="language-plaintext highlighter-rouge">Spring Data Redis</code> 의존성을 추가하면 기본적으로 Lettuce 라이브러리를 Redis 클라이언트로 사용하게 됩니다. 기본적으로 제공하는 Lettuce가 있음에도 분산 락에 Redisson을 사용하는 이유는 무엇일까요?</p>

<p>분산 락에 <code class="language-plaintext highlighter-rouge">Lettuce</code> 대신 <code class="language-plaintext highlighter-rouge">Redisson</code>을 사용하는 이유는 <strong>락 획득 방식</strong> 차이점에 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">Lettuce</code>는 스레드가 락 획득 대기 상태일 경우, <code class="language-plaintext highlighter-rouge">spin lock</code> 방식으로 대기하게 됩니다. 많은 스레드가 스핀 락으로 Redis에 락을 요청하게 될 경우 Redis에 큰 부하가 생길 수 있습니다. 반면에 <code class="language-plaintext highlighter-rouge">Redisson</code>은 락 획득 방식이 <code class="language-plaintext highlighter-rouge">pub/sub</code> 방식으로 구현되어 있기 때문에 스핀 락 방식보다는 Redis에 부하 부담이 줄어들게 됩니다. 더불어 <code class="language-plaintext highlighter-rouge">Redisson</code>은 락 획득 재시도를 기본 로직으로 제공해주기 때문에 편리하게 Lock을 사용할 수 있게 해줍니다.</p>

<h1 id="redisson-lock-예제-코드">Redisson Lock 예제 코드</h1>

<p>아래는 사이드 프로젝트에서 <code class="language-plaintext highlighter-rouge">Redisson</code>을 활용하여 분산 락을 구현한 코드입니다. 동시성 이슈가 발생할 수 있는 작업을 수행하기 전에 분산 락을 획득하고, 작업을 마쳤다면 락을 반납하면 됩니다. 이로써 여러 스레드가 동시에 접근하더라도 동시성 문제가 발생하지 않게 됩니다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Service</span>
<span class="nd">@Slf4j</span>
<span class="nd">@RequiredArgsConstructor</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">RedissonLockService</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">RedissonClient</span> <span class="n">redissonClient</span><span class="o">;</span>

    <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">tryLock</span><span class="o">(</span><span class="nc">String</span> <span class="n">key</span><span class="o">,</span> <span class="kt">long</span> <span class="n">waitTime</span><span class="o">,</span> <span class="kt">long</span> <span class="n">leaseTime</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">RLock</span> <span class="n">lock</span> <span class="o">=</span> <span class="n">redissonClient</span><span class="o">.</span><span class="na">getLock</span><span class="o">(</span><span class="n">key</span><span class="o">);</span>
        <span class="k">try</span> <span class="o">{</span>
            <span class="k">return</span> <span class="n">lock</span><span class="o">.</span><span class="na">tryLock</span><span class="o">(</span><span class="n">waitTime</span><span class="o">,</span> <span class="n">leaseTime</span><span class="o">,</span> <span class="nc">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">);</span>
            <span class="c1">// waitTime: 락을 기다리는 시간</span>
            <span class="c1">// leaseTime: 락이 자동으로 해제되기까지 유지되는 시간</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">InterruptedException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">log</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="s">"Failed to acquire lock"</span><span class="o">,</span> <span class="n">e</span><span class="o">);</span>
            <span class="k">return</span> <span class="kc">false</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">unlock</span><span class="o">(</span><span class="nc">String</span> <span class="n">key</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">RLock</span> <span class="n">lock</span> <span class="o">=</span> <span class="n">redissonClient</span><span class="o">.</span><span class="na">getLock</span><span class="o">(</span><span class="n">key</span><span class="o">);</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">lock</span><span class="o">.</span><span class="na">isHeldByCurrentThread</span><span class="o">())</span> <span class="o">{</span>
            <span class="n">lock</span><span class="o">.</span><span class="na">unlock</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tryLock</code> 메서드를 통해 락 획득 시도를 하게 됩니다. 획득에 성공한다면 <code class="language-plaintext highlighter-rouge">true</code>를 반환하고, <code class="language-plaintext highlighter-rouge">waitTime</code>동안 락을 획득하지 못한다면 예외가 발생하고 <code class="language-plaintext highlighter-rouge">false</code>를 반환하게 됩니다.</li>
  <li><code class="language-plaintext highlighter-rouge">tryLock</code> 메서드는 <strong>블락킹(blocking) 메서드로, 락을 획득하지 못 한 경우 스레드가 대기 상태에 놓이게 됩니다.</strong></li>
  <li>락 획득 key는 동시성 이슈를 예방하고자 하는 대상의 고유한 식별자가 되어야 합니다. <code class="language-plaintext highlighter-rouge">ex: productId</code></li>
  <li><code class="language-plaintext highlighter-rouge">waitTime</code>동안 락 획득 대기 상태에 놓이게 되며, 락을 사용하던 스레드가 락을 해제하면 <code class="language-plaintext highlighter-rouge">pub/sub</code> 방식을 통해 대기 상태에 놓여있던 스레드에게 락 획득 시도를 하라고 알림을 보내게 됩니다.</li>
  <li>만약 락을 획득하고 작업 시간이 <code class="language-plaintext highlighter-rouge">leaseTime</code>을 넘어가게 되면 자동으로 락이 해제됩니다. 따라서 <code class="language-plaintext highlighter-rouge">leaseTime</code> 이내로 작업이 끝내는 것을 보장해야 동시성 이슈가 발생하지 않습니다.</li>
  <li>작업을 마친 스레드는 <code class="language-plaintext highlighter-rouge">unlock</code>을 통해 락을 해제하게 됩니다.</li>
</ul>

<h1 id="분산-락-활용-예제-코드-재고-차감">분산 락 활용 예제 코드 (재고 차감)</h1>

<p>상품의 재고 수량을 변경시키는 작업은 동시성 이슈가 발생하는 대표적인 예시로 볼 수 있습니다. 여러 스레드가 상품 재고의 수량을 변경하기 위해 동시에 접근할 수 있기 때문입니다.</p>

<p>앞서 살펴본 Redisson을 활용한 분산 락을 재고 수량을 변경하는 로직 전후로 락을 획득/해제를 한다면 동시성 이슈를 예방할 수 있을 겁니다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Transactional</span>
<span class="nd">@Override</span>
<span class="kd">public</span> <span class="nc">Product</span> <span class="nf">decreaseStock</span><span class="o">(</span><span class="nc">String</span> <span class="n">productId</span><span class="o">,</span> <span class="nc">Integer</span> <span class="n">quantity</span><span class="o">)</span> <span class="o">{</span>

    <span class="kt">long</span> <span class="n">leaseTime</span> <span class="o">=</span> <span class="mi">5</span><span class="o">;</span>
    <span class="kt">long</span> <span class="n">waitTime</span> <span class="o">=</span> <span class="mi">10</span><span class="o">;</span>
    <span class="nc">String</span> <span class="n">lockKey</span> <span class="o">=</span> <span class="s">"lock:product:stock:"</span> <span class="o">+</span> <span class="n">productId</span><span class="o">;</span>

    <span class="k">try</span> <span class="o">{</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">redissonLockService</span><span class="o">.</span><span class="na">tryLock</span><span class="o">(</span><span class="n">lockKey</span><span class="o">,</span> <span class="n">waitTime</span><span class="o">,</span> <span class="n">leaseTime</span><span class="o">))</span> <span class="o">{</span> <span class="c1">// 락 획득 시도</span>
        <span class="nc">Optional</span><span class="o">&lt;</span><span class="nc">Product</span><span class="o">&gt;</span> <span class="n">findProduct</span> <span class="o">=</span> <span class="n">productRepository</span><span class="o">.</span><span class="na">findByProductId</span><span class="o">(</span><span class="n">productId</span><span class="o">);</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">findProduct</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
            <span class="k">throw</span> <span class="k">new</span> <span class="nf">IllegalArgumentException</span><span class="o">(</span><span class="s">"Product not found"</span><span class="o">);</span>
        <span class="o">}</span>

        <span class="nc">Product</span> <span class="n">product</span> <span class="o">=</span> <span class="n">findProduct</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>
        <span class="n">product</span><span class="o">.</span><span class="na">decreaseStock</span><span class="o">(</span><span class="n">quantity</span><span class="o">);</span> <span class="c1">// 재고 차감</span>
        <span class="k">return</span> <span class="n">product</span><span class="o">;</span>
      <span class="o">}</span>
    <span class="o">}</span> <span class="k">finally</span> <span class="o">{</span>
      <span class="n">redissonLockService</span><span class="o">.</span><span class="na">unlock</span><span class="o">(</span><span class="n">lockKey</span><span class="o">);</span> <span class="c1">// 락 해제 </span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>상품 고유 식별자(productId)를 사용하여 상품 별로 분산 락을 제어할 수 있도록 했습니다.</li>
  <li>락을 획득한 경우에만 재고 수량을 차감시킬 수 있게 됩니다.</li>
  <li>락 획득에 실패하게 되면 예외가 발생하여, 재고 수량 차감 로직은 수행하지 못 하게 됩니다.</li>
  <li>락 획득 후 작업을 완료했다면 락을 해제해줍니다.</li>
</ul>

<h1 id="분산-락-적용-부분의-aop-분리">분산 락 적용 부분의 AOP 분리</h1>

<p>애플리케이션에서 분산 락과 같은 횡<strong>단 관심사(cross-cutting concern)</strong>는 여러 서비스 메서드에서 반복적으로 구현되기 때문에, 이를 개별 비즈니스 로직과 분리하면 코드의 가독성 및 유지보수성이 크게 향상됩니다. <strong>스프링 AOP</strong>를 활용하면 메서드 호출 전후에 자동으로 락을 획득하고 해제하는 로직을 삽입할 수 있습니다.</p>

<blockquote>
  <p>아래 내용은 AOP에 대한 이해가 필요합니다!</p>
</blockquote>

<h2 id="aop-적용-방법">AOP 적용 방법</h2>

<p>스프링 AOP를 적용하는 방법에 대해 단계별로 알아보겠습니다.</p>

<h3 id="어노테이션-정의">어노테이션 정의</h3>

<p>락이 필요한 메서드에 적용할 커스텀 어노테이션(<code class="language-plaintext highlighter-rouge">@StockLock</code>)을 정의합니다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Target</span><span class="o">(</span><span class="nc">ElementType</span><span class="o">.</span><span class="na">METHOD</span><span class="o">)</span>
<span class="nd">@Retention</span><span class="o">(</span><span class="nc">RetentionPolicy</span><span class="o">.</span><span class="na">RUNTIME</span><span class="o">)</span>
<span class="kd">public</span> <span class="nd">@interface</span> <span class="nc">StockLock</span> <span class="o">{</span>
    <span class="kt">long</span> <span class="nf">waitTime</span><span class="o">()</span> <span class="k">default</span> <span class="mi">5</span><span class="o">;</span>
    <span class="kt">long</span> <span class="nf">leaseTime</span><span class="o">()</span> <span class="k">default</span> <span class="mi">10</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<h3 id="aspect-클래스-작성">Aspect 클래스 작성</h3>

<p><code class="language-plaintext highlighter-rouge">@Around</code> 어드바이스를 활용하여 어노테이션이 붙은 메서드의 <strong>실행 전후에 분산 락 획득 및 해제 로직을 삽입</strong>합니다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Aspect</span>
<span class="nd">@Slf4j</span>
<span class="nd">@Component</span>
<span class="nd">@Order</span><span class="o">(</span><span class="n">value</span> <span class="o">=</span> <span class="nc">Integer</span><span class="o">.</span><span class="na">MAX_VALUE</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span> <span class="c1">// AOP 우선순위를 지정합니다.</span>
<span class="nd">@RequiredArgsConstructor</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">StockAspect</span> <span class="o">{</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">RedissonLockService</span> <span class="n">redissonLockService</span><span class="o">;</span>

    <span class="nd">@Around</span><span class="o">(</span><span class="s">"@annotation(stockLock) &amp;&amp; args(productId,..)"</span><span class="o">)</span>
    <span class="kd">public</span> <span class="nc">Object</span> <span class="nf">doLock</span><span class="o">(</span><span class="nc">ProceedingJoinPoint</span> <span class="n">joinPoint</span><span class="o">,</span> <span class="nc">StockLock</span> <span class="n">stockLock</span><span class="o">,</span> <span class="nc">String</span> <span class="n">productId</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">Throwable</span> <span class="o">{</span>
        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"StockLockAspect.doLock {}"</span><span class="o">,</span> <span class="n">joinPoint</span><span class="o">.</span><span class="na">getSignature</span><span class="o">());</span>

        <span class="kt">long</span> <span class="n">leaseTime</span> <span class="o">=</span> <span class="n">stockLock</span><span class="o">.</span><span class="na">leaseTime</span><span class="o">();</span>
        <span class="kt">long</span> <span class="n">waitTime</span> <span class="o">=</span> <span class="n">stockLock</span><span class="o">.</span><span class="na">waitTime</span><span class="o">();</span>
        <span class="nc">String</span> <span class="n">lockKey</span> <span class="o">=</span> <span class="s">"lock:product:stock:"</span> <span class="o">+</span> <span class="n">productId</span><span class="o">;</span>

        <span class="k">if</span> <span class="o">(</span><span class="n">redissonLockService</span><span class="o">.</span><span class="na">tryLock</span><span class="o">(</span><span class="n">lockKey</span><span class="o">,</span> <span class="n">waitTime</span><span class="o">,</span> <span class="n">leaseTime</span><span class="o">))</span> <span class="o">{</span>
            <span class="k">try</span> <span class="o">{</span>
                <span class="k">return</span> <span class="n">joinPoint</span><span class="o">.</span><span class="na">proceed</span><span class="o">();</span>
            <span class="o">}</span> <span class="k">finally</span> <span class="o">{</span>
                <span class="n">redissonLockService</span><span class="o">.</span><span class="na">unlock</span><span class="o">(</span><span class="n">lockKey</span><span class="o">);</span>
            <span class="o">}</span>
        <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
            <span class="n">log</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="s">"락을 획득하지 못하여 종료합니다. productId={}"</span><span class="o">,</span> <span class="n">productId</span><span class="o">);</span>
            <span class="k">return</span> <span class="kc">false</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<blockquote>
  <p>🚨 AOP 우선 순위 지정</p>

  <p>스프링의 트랜잭션 처리도 AOP를 활용합니다. 이때 분산 락의 AOP와 트랜잭션의 AOP의 순서가 굉장히 중요합니다. 만약 트랜잭션 AOP가 먼저 실행된다면, 여전히 동시성 이슈가 발생할 가능성이 존재하게 됩니다. 따라서 분산 락 AOP를 먼저 적용하기 위해 @Order를 통해 순서를 지정해줍니다. 예제 코드에서는 Integer.MAX_VALUE - 1 값을 지정해주었는데, 이는 트랜잭션의 우선순위는 기본적으로 제일 후순위(INTEGER.MAX_VALUE)이기 때문입니다.</p>
</blockquote>

<h3 id="비즈니스-로직과-분리">비즈니스 로직과 분리</h3>

<p>실제 서비스 메서드는 락 관련 코드를 포함하지 않고, AOP가 이를 대신 처리하게 됩니다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="nd">@Transactional</span>
    <span class="nd">@Override</span>
    <span class="nd">@StockLock</span>
    <span class="kd">public</span> <span class="nc">Product</span> <span class="nf">decreaseStock</span><span class="o">(</span><span class="nc">String</span> <span class="n">productId</span><span class="o">,</span> <span class="nc">Integer</span> <span class="n">quantity</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"product-service: 재고 차감"</span><span class="o">);</span>
        <span class="nc">Optional</span><span class="o">&lt;</span><span class="nc">Product</span><span class="o">&gt;</span> <span class="n">findProduct</span> <span class="o">=</span> <span class="n">productRepository</span><span class="o">.</span><span class="na">findByProductId</span><span class="o">(</span><span class="n">productId</span><span class="o">);</span>

        <span class="k">if</span> <span class="o">(</span><span class="n">findProduct</span><span class="o">.</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
            <span class="k">throw</span> <span class="k">new</span> <span class="nf">IllegalArgumentException</span><span class="o">(</span><span class="s">"Product not found"</span><span class="o">);</span>
        <span class="o">}</span>

        <span class="nc">Product</span> <span class="n">product</span> <span class="o">=</span> <span class="n">findProduct</span><span class="o">.</span><span class="na">get</span><span class="o">();</span>
        <span class="n">product</span><span class="o">.</span><span class="na">decreaseStock</span><span class="o">(</span><span class="n">quantity</span><span class="o">);</span>
        <span class="k">return</span> <span class="n">product</span><span class="o">;</span>
    <span class="o">}</span>
</code></pre></div></div>

<h2 id="aop-적용의-장점">AOP 적용의 장점</h2>

<p>락 획득 및 해제 로직을 한 곳에서 관리하여 여러 서비스 메서드에 <strong>중복된 코드를 제거</strong>할 수 있습니다. 만약 락 처리 로직을 변경할 경우, Aspect 클래스만 수정하면 되므로 <strong>관리가 용이</strong>합니다. 그리고 서비스 메서드에서는 비즈니스 로직에만 집중할 수 있어 코드의 <strong>가독성</strong>이 좋아집니다.</p>

<h1 id="결론">결론</h1>

<p><strong>분산 시스템</strong>에서 동시성 문제를 해결하기 위한 <strong>분산 락은 필수</strong>적인 요소입니다. Redis의 Redisson을 활용하면 높은 성능과 편리한 분산 락 구현이 가능합니다. 또한 AOP를 적용함으로써 락 관련 로직을 분리하면 코드의 유지보수성과 가독성이 크게 향상됩니다. 본 포스트를 참고하여 분산 락을 실제 구현하는 데 도움이 되면 좋겠습니다. 감사합니다.</p>

<h1 id="참고-자료">참고 자료</h1>

<ul>
  <li><a href="https://www.inflearn.com/course/%EB%8F%99%EC%8B%9C%EC%84%B1%EC%9D%B4%EC%8A%88-%EC%9E%AC%EA%B3%A0%EC%8B%9C%EC%8A%A4%ED%85%9C">인프런 - 재고시스템으로 알아보는 동시성이슈 해결방법</a></li>
  <li><a href="https://www.youtube.com/watch?v=4wGTavSyLxE">카카오페이는 어떻게 수천만 결제를 처리할까? 우아한 결제 분산락 노하우 / if(kakaoAI)2024</a></li>
  <li><a href="https://helloworld.kurly.com/blog/distributed-redisson-lock/#2-%EC%A4%91%EB%B3%B5-%EB%B0%9C%EC%A3%BC-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%8F%99%EC%8B%9C-%EC%88%98%EC%8B%A0">풀필먼트 입고 서비스팀에서 분산락을 사용하는 방법 - 마켓 컬리</a></li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="MSA" /><category term="Redis" /><category term="AOP" /><category term="Distributed Lock" /><category term="Redisson" /><summary type="html"><![CDATA[분산 시스템에서 Redis를 이용한 분산 락의 필요성과 분산 락 적용 부분의 AOP 활용 방법을 알아봅시다.]]></summary></entry><entry><title type="html">MSA에서 데이터 일관성 유지를 위한 Saga 패턴</title><link href="http://localhost:4000/spring%20cloud/msa/2025/02/22/MSA-SAGA-Pattern/" rel="alternate" type="text/html" title="MSA에서 데이터 일관성 유지를 위한 Saga 패턴" /><published>2025-02-22T00:00:00+09:00</published><updated>2025-02-22T00:00:00+09:00</updated><id>http://localhost:4000/spring%20cloud/msa/2025/02/22/MSA-SAGA-Pattern</id><content type="html" xml:base="http://localhost:4000/spring%20cloud/msa/2025/02/22/MSA-SAGA-Pattern/"><![CDATA[<blockquote>
  <p>Saga 패턴이 무엇이고, MSA 환겨에서 왜 필요한지 알아봅시다!</p>
</blockquote>

<!-- more -->

<h1 id="-들어가기">📌 들어가기</h1>

<p><strong>마이크로서비스 아키텍처</strong>에서는 각 서비스가 독립적인 데이터베이스를 가지고 있으며, 서비스 간 통신을 통해 비즈니스 로직이 연결되는 경우가 많습니다.</p>

<p>이때, 데이터 일관성을 유지하는 것이 중요한데, 전통적인 <strong>분산 트랜잭션</strong> 방식으로는 한계가 있습니다.</p>

<p>이번 포스트에서는 <strong>Saga 패턴</strong>의 필요성과 이를 도입하지 않을 경우 발생할 수 있는 문제점에 대해 살펴보도록 하겠습니다.</p>

<h1 id="1-전통적인-분산-트랜잭션">1. 전통적인 분산 트랜잭션</h1>

<p>MSA 환경에서 각 서비스는 독립적인 데이터베이스를 가지고 있기 때문에 데이터 정합성을 유지하기가 훨씬 어려워집니다.</p>

<p>전통적인 분산 트랜잭션은 데이터 정합성 불일치 문제를 해결하기 위한 <strong>초기 접근 방식</strong>으로, <strong>여러 데이터베이스에 걸쳐 원자성(Atomicity)을 보장하려는 방식</strong>이었습니다.</p>

<p>그러나 이 방식은 <strong>한계점과 문제점을 동반</strong>하게 되며, 결과적으로 <strong>Saga 패턴</strong>과 같은 대안이 등장하게 되었습니다.</p>

<h2 id="전통적인-분산-트랜잭션-핵심-2-phase-commit2pc">전통적인 분산 트랜잭션 핵심: 2-Phase Commit(2PC)</h2>

<p>MSA <strong>다중 데이터베이스 환경</strong>에서 하나의 비즈니스 로직이 수행될 때, 여러 데이터베이스에 걸쳐 관련 데이터들이 저장됩니다. <strong>전통적인 분산 트랜잭션</strong>에서 가장 널리 사용된 프로토콜로 <code class="language-plaintext highlighter-rouge">2-Phase Commit(2PC)</code>가 있습니다. 이는 <code class="language-plaintext highlighter-rouge">트랜잭션 관리자(Transaction Coordinator)</code>가 존재하여 전체 트랜잭션을 조율하는 방식입니다.</p>

<h2 id="전통적인-분산-트랜잭션-한계점">전통적인 분산 트랜잭션 한계점</h2>

<p>전통적인 분산 트랜잭션 한계점은 다음과 같습니다.</p>

<ul>
  <li>락킹(Locking)으로 인한 성능 저하, 병목 지점이 될 수 있습니다.</li>
  <li>트랜잭션은 관리하는 코디네이터가 <strong>단일 실패 지점</strong>이 될 수 있습니다.</li>
  <li>네트워크 문제로 인해 트랜잭션 관리자의 지시를 받지 못하면, 교착 상태(Deadlock)에 빠질 수도 있습니다.</li>
  <li>관리하는 노드가 많아질수록 트랜잭션을 조율하기 복잡해집니다. 이로 인해 시스템의 확장성이 저하됩니다.</li>
</ul>

<p>💡 위와 같은 한계점들로 인해 전통적인 2PC 방식은 단일 시스템이나 적은 수의 서비스에 적합하지만, <strong>확장성, 고가용성, 비동기성이 중요한 마이크로서비스 환경에는 적합하지 않습니다.</strong></p>

<p>❗️ 참고로, 이번 포스트의 주제는 전통적인 분산 트랜잭션의 한계점으로 인한 Saga 패턴 도입의 필요성을 다루는 포스트입니다. 따라서 전통적인 분산 트랜잭션에 대한 내용은 추후 다른 포스트에서 자세히 다루도록 하겠습니다.</p>

<h1 id="2-전통적인-분산-트랜잭션의-대안">2. 전통적인 분산 트랜잭션의 대안</h1>

<p>전통적인 분산 트랜잭션의 대안으로 <code class="language-plaintext highlighter-rouge">Saga 패턴</code>과 <code class="language-plaintext highlighter-rouge">Outbox 패턴</code>이 있습니다.</p>

<p>두 패턴 중 이번 포스트에서는 Spring Cloud 사이드 프로젝트를 진행하면서 Saga 패턴을 적용한 내용을 다루겠습니다.</p>

<h1 id="3-saga-패턴이란">3. Saga 패턴이란?</h1>

<p>Saga 패턴은 마이크로서비스 간 <strong>분산 트랜잭션을 관리하기 위한 패턴</strong>입니다.</p>

<p>각 서비스의 로컬 트랜잭셩을 통해서 전체 비즈니스 로직의 일관성을 유지하는 방법이죠.</p>

<p><strong>Saga 패턴</strong>의 핵심 아이디어는 하<strong>나의 큰 트랜잭션을 여러 개의 트랜잭션으로 나누고</strong>, 문제가 발생하면 <strong>보상 트랜잭션(Compensating Transaction)</strong>을 수행하여 일관성을 맞추는 것입니다.</p>

<h2 id="3-1-saga-패턴-예시">3-1. Saga 패턴 예시</h2>

<p>Saga 패턴이 무엇인지 이해하기 쉽도록 예시를 들어보겠습니다.</p>

<p>예를 들어, <code class="language-plaintext highlighter-rouge">Order Service -&gt; Payment Service -&gt; Product Service</code> 의 순서로 주문과 결제 그리고 재고 차감이 이뤄지는 비즈니스 로직이 있다고 하겠습니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">Order Service</code>: 주문 생성 -&gt; <code class="language-plaintext highlighter-rouge">ORDER_CREATED</code> 이벤트 발행.</li>
  <li><code class="language-plaintext highlighter-rouge">Payment Service</code>: 결제 요청 -&gt; 결제 성공 시 <code class="language-plaintext highlighter-rouge">PAYMENT_COMPLETED</code> 이벤트 발행.</li>
  <li><code class="language-plaintext highlighter-rouge">Product Service</code>: 재고 차감 -&gt; 만약 재고 부족 시, <strong>실패 이벤트</strong> 발행.</li>
</ol>

<p>🎯 만약 <code class="language-plaintext highlighter-rouge">Product Service</code>에서 재고 부족으로 인해 실패 이벤트가 발생하면, 보상 트랜잭션으로 <strong>주문 취소 및 결제 취소</strong>를 진행해주게 됩니다. 이처럼 실패에 대한 보상 처리를 해주는 것이 Saga 패턴입니다.</p>

<h1 id="4-saga-패턴의-종류">4. Saga 패턴의 종류</h1>

<p>Saga 패턴에는 종류가 존재합니다. 크게 Choreography(코레오그래피) 방식과 Orchestration(오케스트레이션) 방식으로 나뉘게 됩니다.</p>

<p>각 방식에는 장단점이 존재하며, 프로젝트 환경에 따라 적절한 패턴을 적용하면 될 것 같습니다.</p>

<p>그럼, 각 패턴 종류의 장단점을 살펴보겠습니다.</p>

<h2 id="4-1-saga-pattern---choreography코레오그래피">4-1. Saga pattern - Choreography(코레오그래피)</h2>

<p><strong>이벤트 기반</strong>으로 <strong>각 서비스가 직접 이벤트를 구독하고 다음 작업을 수행</strong>하는 패턴입니다. 이는 <strong>중앙 조정자가 없다</strong>는 것이 특징입니다.</p>

<ul>
  <li><strong>장점</strong>: 단순한 구현, 낮은 복잡성</li>
  <li><strong>단점</strong>: 서비스 간 의존성 증가, 복잡한 이벤트 플로우 관리 어려움</li>
</ul>

<p>👉 <strong>예시</strong></p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">Order Service</code> -&gt; <code class="language-plaintext highlighter-rouge">ORDER_CREATED</code> 주문 생성 이벤트 발행</li>
  <li><code class="language-plaintext highlighter-rouge">Payment Service</code> 가 주문 생성 구독 후 결제 처리 -&gt; <code class="language-plaintext highlighter-rouge">PAYMENT_COMPLETED</code> 결제 성공 이벤트 발행</li>
  <li><code class="language-plaintext highlighter-rouge">Delivery Service</code>가 결제 성공 구독 후 배송 요청 처리.</li>
</ol>

<h2 id="4-2-saga-pattern---orchestration오케스트레이션">4-2. Saga Pattern - Orchestration(오케스트레이션)</h2>

<p><strong>중앙 조정자(Service Orchestration)</strong>가 각 서비스에 요청을 보내고 <strong>전체 트랜잭션을 관리 및 조율</strong>하는 패턴입니다.</p>

<ul>
  <li><strong>장점</strong>: 서비스 간 의존성 감소, 중앙 집중식으로 전체 플로우 관리 가능.</li>
  <li><strong>단점</strong>: Orchestrator(중앙 조정자)를 추가 구현해야 하며, 단일 실패 지점(SPOF)이 될 수 있음.</li>
</ul>

<p>👉 <strong>예시</strong></p>

<ol>
  <li><strong>Orchestrator</strong>가 Order Service 에 주문 생성 요청</li>
  <li>주문 생성 -&gt; 결제 요청 -&gt; 재고 차감 -&gt; 배송 요청 순으로 전체 이벤트 발행 및 트랜잭션 관리</li>
  <li>실패 시 보상 트랜잭션을 직접 호출</li>
</ol>

<h2 id="-4-3-saga-pattern-종류-정리">✅ 4-3 Saga Pattern 종류 정리</h2>

<p>Saga 패턴에는 Choreography와 Orchestration 두 방식이 존재합니다.</p>

<p>두 방식은 각각의 장단점이 상반되며, 프로젝트 환경에 알맞게 적절한 패턴 종류를 선택하면 됩니다.</p>

<p>참고로 저는 사이드 프로젝트를 진행할 때 단순한 구현과 낮은 복잡성으로 구성되도록 원했고, 중앙 조정자 도입이 오히려 서비스가 많아질 수록 중앙 조정자를 관리하기 어려워 질 것이란 판단하에 <strong>Choreography(코레오그래피)</strong> 방식을 적용하였습니다.</p>

<h1 id="5-saga-패턴-적용-예제-코드">5. Saga 패턴 적용 예제 코드</h1>

<p>사이드 프로젝트에서 Saga 패턴(Choreography)을 적용한 예제 코드를 보여드리겠습니다.</p>

<p>참고로 실제 코드 전부가 아닌 Saga 패턴 이해를 위한 간소화된 코드로 보여드리겠습니다.</p>

<h2 id="order-service---order_created-이벤트-발행">Order Service - <code class="language-plaintext highlighter-rouge">ORDER_CREATED</code> 이벤트 발행</h2>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Transactional</span>
<span class="nd">@Override</span>
<span class="kd">public</span> <span class="nc">OrderDto</span> <span class="nf">createOrder</span><span class="o">(</span><span class="nc">OrderDto</span> <span class="n">orderDto</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Order-service: 주문 생성"</span><span class="o">);</span>
    
    <span class="c1">// 주문 생성 로직 ...</span>

    <span class="c1">// ORDER_CREATED 이벤트 발행</span>
    <span class="nc">OrderCreatedEvent</span> <span class="n">orderCreatedEvent</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OrderCreatedEvent</span><span class="o">(</span>
            <span class="n">order</span><span class="o">.</span><span class="na">getOrderId</span><span class="o">(),</span>
            <span class="nc">BigDecimal</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">totalPrice</span><span class="o">),</span>
            <span class="n">orderDto</span><span class="o">.</span><span class="na">getPaymentInfos</span><span class="o">(),</span>
            <span class="n">orderDto</span><span class="o">.</span><span class="na">getDeliveryInfo</span><span class="o">());</span>
    <span class="n">orderEventProducer</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="no">ORDER_CREATED</span><span class="o">,</span> <span class="n">orderCreatedEvent</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<h2 id="payment-service---order_created-이벤트-구독-후-결제-처리">Payment Service - <code class="language-plaintext highlighter-rouge">ORDER_CREATED</code> 이벤트 구독 후 결제 처리</h2>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@KafkaListener</span><span class="o">(</span><span class="n">topics</span> <span class="o">=</span> <span class="s">"ORDER_CREATED"</span><span class="o">,</span> <span class="n">groupId</span> <span class="o">=</span> <span class="s">"${spring.kafka.consumer.group-id:payment-service-group}"</span><span class="o">)</span>
<span class="kd">public</span> <span class="kt">void</span> <span class="nf">consume</span><span class="o">(</span><span class="nc">ConsumerRecord</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">record</span><span class="o">)</span> <span class="kd">throws</span> <span class="nc">JsonProcessingException</span> <span class="o">{</span>
    <span class="k">try</span> <span class="o">{</span>
        <span class="nc">String</span> <span class="n">message</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="na">value</span><span class="o">();</span>
        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Consumed message: {}"</span><span class="o">,</span> <span class="n">message</span><span class="o">);</span>
        <span class="nc">OrderCreatedEvent</span> <span class="n">orderCreatedEvent</span> <span class="o">=</span> <span class="n">objectMapper</span><span class="o">.</span><span class="na">readValue</span><span class="o">(</span><span class="n">message</span><span class="o">,</span> <span class="nc">OrderCreatedEvent</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
        <span class="n">log</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"Order created event: {}"</span><span class="o">,</span> <span class="n">orderCreatedEvent</span><span class="o">);</span>

        <span class="n">paymentHandler</span><span class="o">.</span><span class="na">handle</span><span class="o">(</span><span class="n">orderCreatedEvent</span><span class="o">);</span> <span class="c1">// 결제 처리 </span>
    <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">log</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="s">"Error Consume OrderCreatedEvent"</span><span class="o">,</span> <span class="n">e</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>만약, 결제 처리 실패 시 보상 트랜잭션을 수행합니다.</p>

<p><code class="language-plaintext highlighter-rouge">PAYMENT_FAILED</code> 이벤트 발행 -&gt; <code class="language-plaintext highlighter-rouge">Order Service</code>에서 결제 실패를 구독하여 주문 취소를 진행합니다.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kt">void</span> <span class="nf">handle</span><span class="o">(</span><span class="nc">Event</span> <span class="n">event</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">try</span> <span class="o">{</span>
        <span class="n">handleEvent</span><span class="o">(</span><span class="n">event</span><span class="o">);</span>
    <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">handleException</span><span class="o">(</span><span class="n">event</span><span class="o">,</span> <span class="n">e</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">private</span> <span class="kt">void</span> <span class="nf">handleException</span><span class="o">(</span><span class="nc">Event</span> <span class="n">event</span><span class="o">,</span> <span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">log</span><span class="o">.</span><span class="na">error</span><span class="o">(</span><span class="s">"Error handling payment"</span><span class="o">,</span> <span class="n">e</span><span class="o">);</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">event</span> <span class="k">instanceof</span> <span class="nc">OrderCreatedEvent</span> <span class="n">orderCreatedEvent</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">paymentEventProducer</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="no">PAYMENT_FAILED</span><span class="o">,</span> <span class="k">new</span> <span class="nc">PaymentFailedEvent</span><span class="o">(</span>
                <span class="n">orderCreatedEvent</span><span class="o">.</span><span class="na">getOrderId</span><span class="o">(),</span>
                <span class="kc">null</span><span class="o">,</span>
                <span class="no">FAILED</span><span class="o">,</span> <span class="n">e</span><span class="o">.</span><span class="na">getMessage</span><span class="o">()));</span>
    <span class="o">}</span>
    <span class="o">...</span>
<span class="o">}</span>
</code></pre></div></div>

<h1 id="6-saga-패턴-도입-시-장점">6. Saga 패턴 도입 시 장점</h1>

<p>분산 트랜잭션 처리를 위해 Saga 패턴을 도입하면 다음과 같은 장점이 있습니다.</p>

<h2 id="6-1-데이터-정합성-보장">6-1. 데이터 정합성 보장</h2>

<p>서비스 간 비동기 처리에도 Eventually Consistent(최종 일관성) 상태를 유지할 수 있습니다. 예를 들어, 주문 생성 후 결제를 실패한다면, 주문을 취소하여 데이터 불일치를 방지할 수 있습니다.</p>

<p>이처럼, 보상 트랜잭션을 통해 데이터 일관성이 유지됩니다.</p>

<h2 id="6-2-마이크로서비스-독립성-유지">6-2. 마이크로서비스 독립성 유지</h2>

<p>각 서비스는 로컬 트랜잭션만 관리하면 되므로, 강한 결합(Tightly Coupled)을 피할 수 있습니다.</p>

<h2 id="6-3-확장성-향상">6-3. 확장성 향상</h2>

<p>서비스 간의 직접적인 의존성이 줄어들어, 새로운 서비스 추가 및 확장이 쉬워지게 됩니다.</p>

<h1 id="7-saga-패턴을-도입하지-않으면-발생하는-문제점">7. Saga 패턴을 도입하지 않으면 발생하는 문제점</h1>

<h2 id="7-1-데이터-불일치">7-1. 데이터 불일치</h2>

<p>실패 시 적절한 보상 트랜잭션이 없다면, <strong>결제 실패</strong>나 <strong>재고 부족</strong> 등의 시나리오에서, 주문 상태는 <strong>“완료”</strong>이지만 실제로는 결제가 되지 않은 주문이 발생할 수 있습니다.</p>

<h2 id="7-2-사용자-경험-저하">7-2. 사용자 경험 저하</h2>

<p>주문은 <strong>완료 상태</strong>이고 <strong>결제는 실패</strong>했을 때, 제대로된 보상 트랜잭션 처리를 하지 않는다면 <strong>“주문 정상 처리”</strong>라는 잘못된 정보를 사용자에게 전달할 수도 있습니다.</p>

<h1 id="-결론">🎯 결론</h1>

<ul>
  <li>Saga 패턴은 마이크로서비스 환경에서 <strong>데이터 정합성을 유지하기 위한 필수 설계 패턴</strong>으로 볼 수 있습니다.</li>
  <li>보상 트랜잭션을 통해 실패 시에도 전체 시스템의 일관성을 유지할 수 있으며, 서비스 간 결합도를 낮춰 <strong>확장성</strong>과 <strong>유연성</strong>을 확보할 수 있도록 도와줍니다.</li>
</ul>

<p>Kafka와 같은 이벤트 드리븐 기반의 MSA 환경에서 Saga 패턴을 도입하지 않으면, 데이터 불일치 및 비즈니스 오류가 발생할 가능성이 높습니다. 안정적인 시스템을 만들기 위해서는 반드시 <strong>Saga 패턴과 같은 분산 트랜잭션 관리 기법</strong>이 필요합니다.</p>

<h1 id="-추가로-공부하면-좋을-내용">💡 추가로 공부하면 좋을 내용</h1>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP 이론</a></li>
  <li><a href="https://ko.wikipedia.org/wiki/2%EB%8B%A8%EA%B3%84_%EC%BB%A4%EB%B0%8B_%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C">2-Phase Commit</a></li>
  <li>Outbox 패턴</li>
</ul>

<hr />]]></content><author><name>Bang Seung IL</name></author><category term="Spring Cloud" /><category term="MSA" /><category term="Saga pattern" /><summary type="html"><![CDATA[Saga 패턴이 무엇이고, MSA 환겨에서 왜 필요한지 알아봅시다!]]></summary></entry></feed>